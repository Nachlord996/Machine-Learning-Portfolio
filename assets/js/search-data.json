{
  
    
        "post0": {
            "title": "Respuesta a una campaña de mail usando Naive Bayes",
            "content": "Validación de un modelo: Respuesta a una campaña de mail usando Naïve Bayes . # . La calidad de un modelo de Machine Learning no se evalúa exclusivamente con los resultados que este genera durante su entrenamiento y validación. La aplicabilidad de cualquier modelo debe considerar múltiples métricas que demuestren su efectividad en la realidad. . Evaluar incorrectamente un modelo podría generar expectativas irrealistas de su funcionamiento, las cuales harán aparecer problemas en la fase de producción, al utilizar el modelo con datos de la realidad. . Por tanto, el desempeño real de un modelo podría no ser aceptable y en muchos casos generar daños elevados para los clientes, incluyendo dinero y vidas. Un error frecuente de los analistas, es sobredimensionar el funcionamiento de un modelo en base al porcentaje de precisión que arroje. . El objetivo de este documento será evaluar distintas técnicas de validación de modelos de Machine Learning para un caso particular. . Escenario . Para este caso, utilizaremos la herramienta de Rapidminer para generar datos de ejemplo. El objetivo es predecir si una persona responderá a una campaña de marketing por mail utilizando atributos demográficos. . Para ello, existe un operador en Rapidminer “Generate Direct Mailing Data”. Este operador utiliza dos parámetros: . Número de ejemplos a generar. En este caso usaré 10000. | Semilla local. Activar este parámetro me permitirá repetir el ejercicio manteniendo los datos generados. | . Preparación de Datos . El operador de generación arroja un dataset del tamaño indicado con los siguientes predictores: . Nombre | Edad | Estilo de vida (Tres categorías: Activo, Cómodo o Saludable) | Código Postal | Estado Civil | Tipo de vehículo (Dos categorías: Práctico o Costoso) | Deporte (Tres deportes distintos: Bádminton, Fútbol y Atletismo) | Salario | Respuesta al mail | . Antes de comenzar a trabajar, fue necesario realizar algunos ajustes. En primer lugar, la variable a predecir (Si la persona realmente responderá a la campaña por mail) tiene dos posibles valores Response / No Responde, por lo que se puede tratar esta variable como Binomial. . El dataset completo está etiquetado, por lo que podremos dividirlo en dos para separar en Entrenamiento y Test. Aplicaremos la regla del 80/20 y además configuraremos un Split Validation para el dataset de entrenamiento. En este caso, la validación tendrá una proporción 70/30. . El flujo resultante es el siguiente: . . Modelo . Al enfrentarnos a un problema supervisado de clasificación binaria, disponemos de una gran variedad de modelos para probar. Sin embargo, como el objetivo es analizar las métricas de Performance, optaremos por un modelo sencillo de Naive Bayes sin pensar mucho en cuál será el más adecuado. . Dentro del operador de Split Validation, ubiqué el operador de Naive Bayes, aplicación del modelo y luego un operador de Performance activando las siguientes opciones: . Accuracy | False positive | False negative | True positive | True negative | Sensivity | Specificity | AUC | . Por último, utilicé el dataset reservado como Hold-out para testear el modelo generado. A nivel principal del flujo, se debe agregar un operador de Apply Model con el Dataset de test. . Como última medida de performance, agregué una Lift Chart a la salida del Apply Model. Este gráfico apuntará al valor de la clase a predecir “Response”. . Resultados . El proceso de Rapidminer genera la siguiente matriz de confusión para los resultados del dataset de entrenamiento: .   Response reales No Response reales . Response Predichos | 56 | 33 | . No Response Predichos | 15 | 136 | . Si tomamos como clase positiva a los valores “Response”, obtendremos los siguientes datos: . Falsos positivos (FP): 33 | Falsos negativos (FN): 15 | Verdaderos positivos (TP): 56 | Verdaderos negativos (TN): 136 | . Para estos valores, podemos verificar las métricas teóricas y contrastarlas con los resultados de Rapidminer. . Sensibilidad: TP / (TP + FN) 56 / (56 + 15) = 56 / 71 = 0.788 =&gt; 78.8% . Especificidad: TN / (TN + FP) 136 / (136 + 33) = 136 / 169 = 0.804 = 80.4% . Estos valores son idénticos a los calculados automáticamente por Rapidminer: . . Resulta interesante analizar los valores de Class Recall. Puntualmente, estos valores representan la proporción en que una clase dada de los datos fue predicha correctamente. . Este valor tiende a ser influenciado por la representación de la clase en el Dataset. Es decir, el modelo podrá comportarse adecuadamente en general, pero muy deficientemente para una clase en particular. Este efecto se maximiza cuando otras clases están sobrerepresentadas en el Dataset. Cuando esto sucede, se dice que el Dataset está desbalanceado. . En este caso, el Recall para los “No Response” es mayor que el Recall para los “Response”. Si analizamos la representación de cada clase en el dataset inicial, podemos ver que realmente existe una relación entre los valores resultantes y la proporción de las clases. . . Con respecto a la curva ROC y el valor AUC, podemos decir que el modelo se comporta relativamente bien. El valor resultante del área bajo la curva es de 0.861. Supera el valor de la elección aleatoria, donde el área sería de 0.5. . . Tomando en consideración este mismo concepto de mejora sobre la selección aleatoria, la confianza de predicción del modelo va a ser distinta para cada uno de los valores que clasifica. . A partir de esta información, centrándonos en los verdaderos positivos, es posible construir un gráfico que muestre como varía la mejora del modelo en función de la confianza. . De esta manera, es posible saber la mejora sobre la elección aleatoria, en definitiva, que tan bien funciona un modelo, tomando parte de la población total. . En este caso encontré que la cobertura alcanza el 70% en la tercera barra del gráfico. Este dato es interesante porque significaría que un 30% de la población es necesaria para lograr un 70%. . .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Naive-Bayes.html",
            "relUrl": "/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Naive-Bayes.html",
            "date": " • Nov 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Efecto De La Estandarización Y Normalización",
            "content": "Efecto de la estandarización y normalización . En la mayoría de los modelos de Machine Learning, es recomendable partir de datos estandarizados o normalizados para obtener un mejor desempeño del modelo a entrenar. Por esta razón, resulta interesante verificar el efecto de estas transformaciones previas en el resultado final del modelo. . Para evaluar empíricamente este efecto, se propone utilizar la herramienta Rapidminer y generar un flujo que valide la precisión de un modelo en particular. Para esto, el flujo deberá verificar la métrica, a partir de un modelo entrenado con datos estandarizados (o normalizar) y otro con datos sin estandarizar (o normalizar). . El dataset a utilizar será Wine UCI y el modelo a entrenar será del tipo clasificador Naive Bayes. . A los efectos de entender mejor la problemática, resulta conveniente explicitar la diferencia entre los conceptos “normalización” y “estandarización”. Si bien ambas técnicas implican llevar los predictores a una escala común, su implementación es distinta. La normalización se centra en el intervalo objetivo de la transformación, escalando los valores según su proporción original (p.e.: El intervalo 0.0 a 1.1). Por otra parte, la estandarización implica llevar los valores de los atributos a un conjunto con media cero y desviación estándar uno. . Para comenzar se crea un nuevo flujo en Rapidminer y se agregan los operadores de Naive Bayes. Cada uno de los operadores se nutren con el modelo Wine UCI, con el detalle de que uno de ellos recibe los datos normalizados utilizando “Transformación Z” en la configuración del operador. . . El modelo por evaluar no debería ser afectado por las escalas de los atributos, ya que la base del algoritmo es la probabilidad condicional y no implica un cálculo de distancia. . Al ejecutar el flujo de Rapidminer se obtienen como salidas las siguientes matrices de confusión: . Modelo sin normalización . . Modelo normalizado . . Como conclusión, se verificó para un caso particular, que la estandarización o normalización de los datos no impacta significativamente en la precisión de un modelo Naive Bayes. Esto condice con la teoría mencionada anteriormente sobre la base del modelo. Sin embargo, existen diversos modelos de Machine Learning de clasificación que requieren la normalización para funcionar correctamente, por lo que este experimento no es suficiente para descartar la técnica de normalización en la preparación de los datos. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/24/Efecto-de-la-estandarizaci%C3%B3n-y-normalizaci%C3%B3n.html",
            "relUrl": "/2021/11/24/Efecto-de-la-estandarizaci%C3%B3n-y-normalizaci%C3%B3n.html",
            "date": " • Nov 24, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Lda Utilizando Python Y Scikit",
            "content": "LDA utilizando Python y Scikit-learn . Los algoritmos lineales son de gran utilizar para atacar problemas relativamente sencillos, donde es notaria una relación lineal entre los predictores y la variable objetivo. . En esta ocasión se utilizará el algoritmo de Análisis de Discriminante Lineal para un problema de clasificación binaria. Para ello, se utilizará la librería de Scikit-learn de Python que provee métodos de entrenamiento para un modelo LDA. . Se cuenta con un Dataset simple de únicamente dos variables: X e Y. Es importante destacar que la cantidad de ejemplos no es muy grande, hay solamente 20 registros. La clase por predecir tiene dos posibles valores 0 y 1. . Importar librerías y lectura de Dataset . Para este proceso se utilizarán las librerías de Scikit-learn, Matplotlib y Pandas. Para evitar complicaciones mayores accederé a un documento de Google Colab y escribiré el código Python en un Jupyter Notebook. . . Graficar Dataset en dos dimensiones . Al disponer de únicamente dos variables, la linealidad del problema puede verse representada mediante un gráfico de tipo “Plot” de ambos predictores. Esto puede ser realizado mediante la librería Matplotlib, manipulando previamente las columnas al invocar el método de graficar. . . En el gráfico se ve claramente la separación de ambas clases en dos grupos disjuntos. Por lo tanto, podemos asegurar que la utilización de un modelo lineal para trabajar este Dataset es apropiada. . Entrenamiento del modelo . Habiendo confirmado la disposición de las clases en el gráfico plot, el siguiente paso implicar entrenar un modelo LDA utilizando el Dataset. Para ello, primero es necesario separar los predictores de la variable objetivo. . . El método train_test_split permite generar cuatro conjuntos a partir del Dataset. Separa los datos en predictores y variable objetivo. Además, aparta algunos datos para utilizar como validación del modelo. En este caso se utilizará el 25% (5 ejemplos) del Dataset para validación. . . Para entrenar el modelo LDA se utilizan los métodos importados de scikit-learn. . . ## . Validación del modelo . Para validar el entrenamiento del modelo, utilizaremos los ejemplos que mantuvimos fuera del entrenamiento. Es importante tener también los valores reales de la variable objetivo para poder compararlos con las predicciones del modelo. . . Los resultados muestran que el modelo realizó una predicción correcta en todos los casos de validación. También es de utilidad examinar la matriz de confusión de las pruebas. . Esto se puede realizar mediante el método confusion_matrix de Scikit-learn Metrics. . . Cada columna representa las predicciones que el modelo realizó, mientras que las filas los valores reales tomados del Dataset de validación. Si todos los valores de la matriz con ceros a excepción de la diagonal principal, el modelo habrá funcionado perfectamente. En caso contrario nos encontraremos con falsos positivos o falsos negativos, situaciones donde el modelo realizó la predicción incorrecta. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/02/LDA-utilizando-Python-y-Scikit.html",
            "relUrl": "/2021/11/02/LDA-utilizando-Python-y-Scikit.html",
            "date": " • Nov 2, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Preparación De Datos Con Python",
            "content": "Preparación de datos con Python . Actualmente existen múltiples herramientas que permiten una exploración profunda sobre los datos iniciales, las cuales son de gran utilidad para el analista que decide comenzar con este proceso. Desde una planilla de cálculo como Microsoft Excel, hasta módulos especializados en herramientas productivas, existen diversos mecanismos para llevar a cabo la preparación de los datos, teniendo como objetivo generar los insumos para un modelo de Machine Learning. . En esta ocasión, se pretende investigar los distintos mecanismos que dispone Python y las librerías desarrolladas por la comunidad, para el análisis y tratamiento de datos. . Todo el código Python será escrito en un Jupyter Notebook, aprovechando las facilidades que este tipo de documentos ofrece para la ejecución de este. Además, utilizaré la herramienta Google Colab, la cual resuelve las referencias a las librerías de Python a utilizar automáticamente. . Importar librerías y lectura del Dataset . El primer paso consiste en importar todas las librerías a utilizar durante el proyecto. . NumPy . | Pandas . | Seaborn . | MatPlotLib . | . Luego se debe leer el contenido del archivo “Titanic-Dataset.csv”. Al ejecutar el código se puede visualizar una vista previa de los registros. Debería verse de esta manera: . . Visualizar Dataset . Por medio de las siguientes instrucciones es posible identificar las columnas con valores numéricos. El resto de los atributos son de tipo categórico. . . La generación de gráficos para visualizar el Dataset puede realizarse mediante la librería Seaborn. Para ejemplificar, es posible generar un gráfico que ilustre la tasa de sobrevivientes, partiendo de la clase y el sexo del individuo. . . ## . Valores faltantes e imputación . Este Dataset presenta valores faltantes únicamente en los atributos Age, Cabin y Embarked. Para verificar esto, se utiliza el siguiente código: . . Como se puede ver en este conteo de valores faltantes, los atributos más impactados son Age y Cabin. En el caso de edad, será necesario aplicar una imputación de valores, siendo este atributo importante en la predicción del modelo. Probablemente, los atributos Cabin y Embarked no impacten significativamente en el desempeño del modelo, por lo que se podría considerar eliminarlos. . La eliminación de atributos se realiza con el siguiente código. Además se eliminará el número de ticket, el cual no aporta ninguna información para la predicción. . . . Para decidir el valor que será imputado al atributo edad, es conveniente analizar la distribución de este. Esto se puede realizar mediante la librería matplotlib. . . La distribución observada es bastante centrada pero algo inclinada hacia un lado, por lo que una buena decisión sería imputar la edad utilizando la mediana de los datos. Esto se realiza mediante el siguiente código: . . Al concluir este paso, tenemos asegurado que los datos no contienen datos faltantes. Por lo que serán de mayor utilidad y precisión a la hora de entrenar el modelo. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/29/Preparaci%C3%B3n-de-datos-con-Python.html",
            "relUrl": "/2021/10/29/Preparaci%C3%B3n-de-datos-con-Python.html",
            "date": " • Oct 29, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Árboles De Decisión Para Problemas De Regresión, Housing Uci",
            "content": "Al igual que los problemas de clasificación vistos en artículos anteriores, los árboles de decisión son una herramienta muy intuitiva para atacar los problemas supervisados de regresión. En este tipo de problemas, el objetivo será predecir el valor de una variable continua a partir de un modelo generado con predictores mayormente numéricos. . Los árboles de decisión están dentro del grupo de Algoritmos No Lineales, los cuales hacen menos suposiciones acerca de la estructura de los datos y/o la naturaleza del problema. También cuentan con la ventaja de una mayor interpretabilidad del modelo generado. Un árbol de decisión se representa frecuentemente como un árbol binario donde cada nodo representa una condición a evaluar con respecto a un predictor en particular, y cada hoja alberga un posible valor de la variable de salida. Esta representación permite una rápida evaluación de un nuevo ejemplo para poder obtener la predicción con respecto al mismo. . Por tanto, la complejidad de los árboles de decisión radica en la configuración de los parámetros del modelo, los cuales permiten generar distintas versiones del árbol en base a los valores escogidos. . Criterio . | Profundidad máxima . | Confianza . | Ganancia mínima . | Mínimo tamaño de hoja . | Otros . | . Contexto . Para este ejercicio se utilizará un Dataset provisto por la Univeridad de California Irvine (UCI) de precios de inmuebles bajo el nombre de distribución “Housing”. Este es un Dataset clásico utilizado en problemas de regresión, donde se intenta predecir la mediana de casas ocupadas por los dueños. . Datos . El mismo cuenta con 12 predictores numéricos continuos y 1 binomial. Los atributos del dataset son los siguientes: . CRIM – Proporción de crimen per cápita . | ZN – Proporción de terreno residencial ubicado en solares mayors a 25.000 metros cuadrados. . | INDUS – Proporción de acres de negocios no-retail por pueblo . | CHAS – Contacto con el río Charles { Sí, No} . | NOX – Concentración de óxido nítrico . | RM – Número promedio de habitacione . | AGE – Proporcion de unidades ocupadas por dueños que fueron construidas antes de 1940 . | DIS – Distancias ponderadas a 5 Centros de empleo de Boston . | RAD – Índice de accesibilidad a autopistas periféricas . | TAX – Proporción de impuestos del valor total por cada 10000 USD . | PTRATIO – Proporción de Profesor y Estudiantes en pueblo . | B - Proporción de gente negra . | LSTAT – Porcentaje de estatus más bajo de la población . | . El Dataset comprende 506 valores únicos y se encuentra totalmente completo, es decir ningún predictor contiene valores faltantes. . Modelo . Tras analizar la completitud y buen estado de los datos, se debe implementar el modelo y analizar sus resultados. Para ello, haré un flujo nuevo en Rapidminer que utilice el operador de Árbol de decisión. A partir del Dataset “Housing”, generaré dos conjuntos según la regla 70/30. El primero será destinado a entrenamiento y el segundo a testing del modelo. . Además, utilizaré en esta ocasión un K-Fold Cross Validation para obtener un resultado más realista con respecto a este Dataset que es de un tamaño reducido. Este operador nos permitirá dividir el Dataset en K particiones o “Folds”, entrenar K modelos distintos, reservando cada una de esas particiones para test en cada iteración. . El flujo en Rapidminer se debería ver de la siguiente manera: . . . Al ejecutar este modelo, Rapidminer obtenemos como resultados como la visualización del árbol generado que podrá darnos más información sobre el ajuste de los parámetros. También el vector de Performance indicando los valores de Raíz cuadrada del error medio (RMSE), el error absoluto y el error medio de predicción. . Se analizaron distintos valores de hyperparámetros para el árbol de decisión de regresión para obtener distintos resultados. . A continuación, se registran los mejores valores encontrados por método de tanteo y observación. . Profundidad Mejora mínima Tamaño de hoja mínimo Alternativas de prepruning RMSE Error absoluto Error relativo . 10 | 0.01 | 5 | 10 | 4.795 | 3.009 +/- 3.734 | 14.11% +/- 14.90% | .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/18/%C3%81rboles-de-Decisi%C3%B3n-para-problemas-de-regresi%C3%B3n,-Housing-UCI.html",
            "relUrl": "/2021/10/18/%C3%81rboles-de-Decisi%C3%B3n-para-problemas-de-regresi%C3%B3n,-Housing-UCI.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Direccionamiento De Una Campaña De Marketing Para Ereaders",
            "content": "En múltiples ocasiones, los equipos de marketing deberán estimar la mejor estrategia para vender un nuevo producto. Especialmente cuando se trata de una marca establecida, direccionar la estrategia para los clientes potenciales determina el éxito del lanzamiento del producto. Estos casos son especiales, ya que es muy alta la probabilidad de que se disponga de datos sobre los productos anteriormente lanzados. . En base a datos históricos, es posible entrenar un modelo que permita determinar si un cliente comprará el nuevo producto cuando este sea anunciado. En este caso, se estudiará un Dataset con información de los patrones de comportamiento de los clientes en sus actividades en el sitio web de una empresa de E-Readers. . Contexto . Se dispone de dos Dataset con información de los clientes. Uno de ellos está completamente etiquedado de acuerdo con las compras realizadas de los clientes. La variable objetivo a predecir es del tipo nominal, por lo que tiene múltiples y determinados valores posibles. . Por su parte, el segundo Dataset no contiene esta variable, el mismo corresponde a información actual de los perfiles de los clientes. A partir de éste, se deberán predecir las clases en la etapa de testeo del modelo. . Naturalmente este tipo de problema se tratará con un modelo supervisado de clasificación, ya que es de nuestro interés predecir la clase de clientes sin clasificar. . Para este ejercicio, se utilizará un modelo de Árbol de Decisión en Rapidminer. El objetivo será examinar y comparar el funcionamiento de este tipo de algoritmo no lineal para un ejercicio de clasificación. . Datos . Los árboles de decisión son modelos de Machine Learning que requieren poca preparación de los datos, ya que son bastantes permisivos con valores faltantes, distribuciones sesgadas y distintos tipos de datos. . Con respecto a este último punto, la siguiente tabla muestra información sobre los predictores disponibles: . Predictor Rango Comentario . ID | - | Identificador del cliente | . Edad | - | Variable numérica | . EstadoCivil | C - S | Variable binomial | . Sexo | F – M | Variable binomial | . ActividadWebsite | Escasa – Regular - Frecuente | Variable nominal | . ComproElectronicos12 | SI – NO | Variable binomial | . MiroElectronicos12 | SI – NO | Variable binomial | . ComproMedios18 | SI – NO | Variable binomial | . ComproLibrosDigitales | SI - NO | Variable binomial | . MetodoPago | Transferencia Bancaria – Cuenta Website – Tarjeta Credito – Debito Mensual | Variable nominal | . En este caso, la mayoría de variables son categóricas. Considero que todos los datos proporcionados son relevantes para el ejercicio, a excepción del identificador del cliente. Este dato no es de utilidad para la predicción, ya que se trata de una referencia a un registro en particular. . Este tipo de datos puede ser excluido del Dataset desde el inicio. Sin embargo, en este caso usaré una ventaja que aporta Rapidminer, cambiaré el tipo de dato a “Identificador”. De esta manera, se mantendrá a lo largo del flujo, pero no influirá en el entrenamiento del modelo. . . Por medio del operador “Set Role” es posible modificar el papel de ese atributo en Rapidminer. En la siguiente imagen se puede ver como son diferenciados de los demás. . . Modelo . Agregamos un operador de Árbol de Decisión en el flujo de Rapidminer. El mismo usará el dataset de entrenamiento como entrada. El modelo resultante será probado mediante el operador “Apply Model”, usando el Dataset de Test. . El flujo resultante se ve de la siguiente manera: . . Al ejecutar el modelo con los datos de prueba, vemos que Rapidminer agrega 4 atributos de confianza y un atributo adicional para la predicción de la clase objetivo. . Cada una de estas confianzas indican que tan probable es que el modelo clasifique el registro en cada una de las 4 clases. Por tanto, la suma de todas las confianzas da como resultado 1. . . La probabilidad obtenida para cada registro corresponde a la proporción de ejemplos de clases distintas que durante el entrenamiento se generaron en el mismo nodo hoja. . Queda claro que aquellos registros con confianzas más equilibrados tienen menor seguridad de predicción frente a aquellos donde las diferencias son marcadas. . A continuación, voy a seleccionar 3 registros en particular y aplicar modificaciones en los hyperparámetros del árbol de decisión. Esta prueba debería arrojar resultados distintos de clase objetivo, especialmente si los registros elegidos tienen confianzas equilibradas. . Se ejecutarán 4 configuraciones distintas con los siguientes valores de parámetros . Criterio: Gain_Ratio Maximal_Depth: 10 Minimal_Gain: 0.01 . | Criterio: Gini_Index Maximal_Depth: 10 Minimal_Gain: 0.01 . | Criterio: Gain_Ratio Maximal_Depth: 5 Minimal_Gain: 0.05 . | Criterio: Gain_Ratio Maximal_Depth: 20 Minimal_Gain: 0.05 . | ID Cliente Predicción Test 1 Predicción Test 2 Predicción Test 3 Predicción Test 4 . 98200 | Adoptante Temprano 54% | Adoptante Temprano 100% | Adoptante Temprano 41% | MayoriaTardia 84% | . 76655 | MayoriaTardia 84% | Adoptante Temprano 50% | MayoriaTardia 75% | Adoptante Temprano 100% | . 63570 | Adoptante Temprano 100% | Adoptante Temprano 75% | Adoptante Temprano 100% | Adoptante Temprano 100% | . Como conlusión, los parámetros que establecen las distintas operaciones a efectuar sobre el árbol de decisión generan resultados muy distintos entre sí, cambiando la confianza de predicción de algunos registros, incluso la clase predicha en sí. . Este tipo de algoritmo de Machine Learning es fácil de entender, ya que su salida es una representación que podemos entender. El modelo genera un árbol donde en cada nodo se deberá tomar una decisión con respecto a un predictor dado y en sus hojas estarán las clases objetivo a predecir. Por tanto, predecir un nuevo valor implica simplemente recorrer el árbol generado. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/16/Direccionamiento-de-una-campa%C3%B1a-de-marketing-para-eReaders.html",
            "relUrl": "/2021/10/16/Direccionamiento-de-una-campa%C3%B1a-de-marketing-para-eReaders.html",
            "date": " • Oct 16, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}