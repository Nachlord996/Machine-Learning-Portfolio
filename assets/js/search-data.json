{
  
    
        "post0": {
            "title": "Un problema cl√°sico de clasificaci√≥n: UCI Iris mediante K-NN",
            "content": "Dentro de las t√©cnicas para clasificaci√≥n en problemas no lineales, existe un grupo que utiliza la distancia entre predictores como elemento central. Esto parte de la idea de que los ejemplos que pertenecen a una misma clase, ser√°n ciertamente m√°s similares en cuanto a valores de los distintos predictores. . K-nearest Neighbours o simplemente K-NN, es un algoritmo para problemas de clasificaci√≥n que se basa en almacenar la informaci√≥n del dataset y evaluar nuevos ejemplos a partir de un c√°lculo simple de distancia. La clase predicha de un elemento estar√° dada por los K elementos (previamente clasificados) m√°s cercanos. . Contexto . Para este ejercicio se utilizar√° como base el Dataset Iris de UCI, el mismo es de acceso totalmente p√∫blico y gratuito. En Rapidminer generar√© un flujo que entrene un modelo a partir de los datos de Iris, en este caso bajo la proporci√≥n 70/30, para luego testearlo, revisar los resultados y las distintas opciones de configuraci√≥n que el modelo ofrece. . Datos . El Dataset Iris es bastante reducido, cuenta solamente con 150 ejemplos. Adem√°s de la variable objetivo, existen 4 predictores distintos relacionados con medidas de las flores observadas en la realidad. . El dataset est√° completamente etiquetado y ning√∫n predictor tiene valores faltantes. La siguiente tabla resume las variables disponibles en el Dataset: . Variable Tipo de dato . Largo S√©palo | Num√©rico | . Ancho del S√©palo | Num√©rico | . Largo del P√©talo | Num√©rico | . Ancho del P√©talo | Num√©rico | . La variables objetivo es del tipo Polinomial y tiene 3 valores posibles: Iris Setosa, Iris Versi-color e Iris Virginica. . Examinando los gr√°ficos de tipo plot entre los predictores, resulta interesante la agrupaci√≥n generada en el espacio de las clases para las variables ‚ÄúLargo P√©talo‚Äù y ‚ÄúAncho P√©talo‚Äù. Adem√°s, estos dos predictores son los que tienen mayor correlaci√≥n con la variable objetivo. . . Modelo . En Rapidminer, se importa el Dataset de Iris. En primer lugar, es necesario eliminar los predictores que no vamos a utilizar para el ejercicio. Luego, se realiza la separaci√≥n de los datos mediante muestreo aleatorio en 70% para Entrenamiento y 30% para Test, esto se puede realizar mediante el operador ‚ÄúSplit Data‚Äù. . Agregamos el operador de K-NN con la configuraci√≥n que viene por defecto, seguido de un ‚ÄúApply Model‚Äù para predecir los valores de la clase objetivo para el 30% reservado para Test. . El flujo deber√≠a verse as√≠: . . Evaluaci√≥n . Al ejecutar el modelo, vemos que los resultados obtenidos son muy positivos. Esto quiere decir que nuestro modelo aprovech√≥ bien la correlaci√≥n entre predictores y la separaci√≥n en el hyperespacio de las clases objetivo. . Aqu√≠ la matriz de confusi√≥n para esta ejecuci√≥n inicial: . Vale destacar que el operador de K-NN ofrece distintos m√©todos para el c√°lculo de la distincia, los cuales podr√≠an ser interesantes para otras situaciones donde la separaci√≥n no sea tan clara o el resultado obtenido no sea tan bueno. . Distancia de Chebychev | Distancia Euclideana | Similitud Coseno | Distancia de Manhattan | . Tambi√©n, Rapidminer ofrece la posibilidad de ponderar el voto en la selecci√≥n de la clase objetivo. Esto se puede establecer mediante un switch el cual determina si la distancia importa en la decisi√≥n. Es decir, aquellos vecinos cercanos tendr√°n una mayor incidencia en la clase escogida. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html",
            "relUrl": "/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html",
            "date": " ‚Ä¢ Dec 1, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Revisi√≥n de t√©cnincas de aprendizaje no supervisado: K-means",
            "content": "Los m√©todos de aprendizaje autom√°tico se pueden dividir en dos grandes enfoques, los supervisados y los no supervisados. El primero se basa en el uso de Datasets etiquetados. Esta informaci√≥n es utilizado en el entrenamiento de un modelo para que este aprenda las relaciones que existen entre los datos de entrada y una variable objetivo. Por esto mismo, este enfoque se centra en generar la capacidad de predicci√≥n a partir de ejemplos nuevos, con una precisi√≥n aceptable. . Por otra parte, los algoritmos de Machine Learning no supervisados tienen el objetivo de trabajar con datos no etiquetados. No existe una variable objetivo a predecir ni un comportamiento en particular para simular. Este tipo de algoritmos se caracterizan por encontrar patrones y otorgar mayor informaci√≥n sobre un conjunto de datos existente. Dentro de este conjunto se encuentra el algoritmo a tratar en este art√≠culo: K-Means. . K-Means es un algoritmo no supervisado de Clustering. Est√° pensado para descubrir los distintos grupos que puedan existir en un Dataset sin ese conocimiento previamente. . Contexto . En este ejercicio se cuenta una base de datos de pacientes de un hospital. Se desea obtener m√°s informaci√≥n acerca de la influencia del peso, el sexo y el colesterol en el desarrollo de una enfermedad coronaria. . Esta tarea implica detectar la existencia de grupos naturales en los datos que relacionen estos factores mencionados con el desarrollo de la enfermedad. El modelo se entrenar√° utilizando la herramiento Rapidminer. . Datos . Se cuenta con un dataset con 3 variables, dos de estas num√©rcias y una binomial. . Sexo | Peso | Colesterol | . El dataset tiene 547 registros y no hay valores faltantes. Los datos parecen ser correctos y estar expresados en las unidades adecuadas. . . Modelo . En el flujo de Rapidminer se debe agregar un operador K-means que entrenar√° el modelo de clustering. El mismo necesita un par√°metro k que significa la cantidad de clusters a generar. Por conocimiento previo del Dataset, se ingresar√° el valor K = 4, aunque esto normalmente se decide en base a la exploraci√≥n realizada del Dataset. . Adem√°s se puede insertar un operador de visualizaci√≥n de cl√∫steres para poder entender mejor los resultados generados por el modelo. El entrenamiento determina una lista de centroides, puntos en el hyperespacio que representan los centros de los grupos generados. Los dem√°s puntos determinan el grupo al cual pertenecen por medio de la distancia a los centroides. . El flujo se ve de la siguiente manera: . . La salida que genera el √∫ltimo operador aporta un gr√°fico de Scatter Plot que muestra visualmente los grupos generados. La utilidad de este modelo podr√≠a ser identificar personas que pertenezcan a los cl√∫sters de mayor peso y colesterol, ya que estos son los m√°s propensos a desarrollar una enfermedad card√≠aca. . .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/clustering/k-means/rapidminer/2021/11/28/Revision-de-t%C3%A9cnicas-de-aprendizaje-no-supervisado-k-means.html",
            "relUrl": "/clustering/k-means/rapidminer/2021/11/28/Revision-de-t%C3%A9cnicas-de-aprendizaje-no-supervisado-k-means.html",
            "date": " ‚Ä¢ Nov 28, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Validaci√≥n de un modelo: Respuesta a una campa√±a de mail usando Na√Øve Bayes",
            "content": "La calidad de un modelo de Machine Learning no se eval√∫a exclusivamente con los resultados que este genera durante su entrenamiento y validaci√≥n. La aplicabilidad de cualquier modelo debe considerar m√∫ltiples m√©tricas que demuestren su efectividad en la realidad. . Evaluar incorrectamente un modelo podr√≠a generar expectativas irrealistas de su funcionamiento, las cuales har√°n aparecer problemas en la fase de producci√≥n, al utilizar el modelo con datos de la realidad. . Por tanto, el desempe√±o real de un modelo podr√≠a no ser aceptable y en muchos casos generar da√±os elevados para los clientes, incluyendo dinero y vidas. Un error frecuente de los analistas, es sobredimensionar el funcionamiento de un modelo en base al porcentaje de precisi√≥n que arroje. . El objetivo de este documento ser√° evaluar distintas t√©cnicas de validaci√≥n de modelos de Machine Learning para un caso particular. . Escenario . Para este caso, utilizaremos la herramienta de Rapidminer para generar datos de ejemplo. El objetivo es predecir si una persona responder√° a una campa√±a de marketing por mail utilizando atributos demogr√°ficos. . Para ello, existe un operador en Rapidminer ‚ÄúGenerate Direct Mailing Data‚Äù. Este operador utiliza dos par√°metros: . N√∫mero de ejemplos a generar. En este caso usar√© 10000. | Semilla local. Activar este par√°metro me permitir√° repetir el ejercicio manteniendo los datos generados. | . Preparaci√≥n de Datos . El operador de generaci√≥n arroja un dataset del tama√±o indicado con los siguientes predictores: . Nombre | Edad | Estilo de vida (Tres categor√≠as: Activo, C√≥modo o Saludable) | C√≥digo Postal | Estado Civil | Tipo de veh√≠culo (Dos categor√≠as: Pr√°ctico o Costoso) | Deporte (Tres deportes distintos: B√°dminton, F√∫tbol y Atletismo) | Salario | Respuesta al mail | . Antes de comenzar a trabajar, fue necesario realizar algunos ajustes. En primer lugar, la variable a predecir (Si la persona realmente responder√° a la campa√±a por mail) tiene dos posibles valores Response / No Responde, por lo que se puede tratar esta variable como Binomial. . El dataset completo est√° etiquetado, por lo que podremos dividirlo en dos para separar en Entrenamiento y Test. Aplicaremos la regla del 80/20 y adem√°s configuraremos un Split Validation para el dataset de entrenamiento. En este caso, la validaci√≥n tendr√° una proporci√≥n 70/30. . El flujo resultante es el siguiente: . . Modelo . Al enfrentarnos a un problema supervisado de clasificaci√≥n binaria, disponemos de una gran variedad de modelos para probar. Sin embargo, como el objetivo es analizar las m√©tricas de Performance, optaremos por un modelo sencillo de Naive Bayes sin pensar mucho en cu√°l ser√° el m√°s adecuado. . Dentro del operador de Split Validation, ubiqu√© el operador de Naive Bayes, aplicaci√≥n del modelo y luego un operador de Performance activando las siguientes opciones: . Accuracy | False positive | False negative | True positive | True negative | Sensivity | Specificity | AUC | . Por √∫ltimo, utilic√© el dataset reservado como Hold-out para testear el modelo generado. A nivel principal del flujo, se debe agregar un operador de Apply Model con el Dataset de test. . Como √∫ltima medida de performance, agregu√© una Lift Chart a la salida del Apply Model. Este gr√°fico apuntar√° al valor de la clase a predecir ‚ÄúResponse‚Äù. . Resultados . El proceso de Rapidminer genera la siguiente matriz de confusi√≥n para los resultados del dataset de entrenamiento: . ¬† Response reales No Response reales . Response Predichos | 56 | 33 | . No Response Predichos | 15 | 136 | . Si tomamos como clase positiva a los valores ‚ÄúResponse‚Äù, obtendremos los siguientes datos: . Falsos positivos (FP): 33 | Falsos negativos (FN): 15 | Verdaderos positivos (TP): 56 | Verdaderos negativos (TN): 136 | . Para estos valores, podemos verificar las m√©tricas te√≥ricas y contrastarlas con los resultados de Rapidminer. . Sensibilidad: TP / (TP + FN) 56 / (56 + 15) = 56 / 71 = 0.788 =&gt; 78.8% . Especificidad: TN / (TN + FP) 136 / (136 + 33) = 136 / 169 = 0.804 = 80.4% . Estos valores son id√©nticos a los calculados autom√°ticamente por Rapidminer: . . Resulta interesante analizar los valores de Class Recall. Puntualmente, estos valores representan la proporci√≥n en que una clase dada de los datos fue predicha correctamente. . Este valor tiende a ser influenciado por la representaci√≥n de la clase en el Dataset. Es decir, el modelo podr√° comportarse adecuadamente en general, pero muy deficientemente para una clase en particular. Este efecto se maximiza cuando otras clases est√°n sobrerepresentadas en el Dataset. Cuando esto sucede, se dice que el Dataset est√° desbalanceado. . En este caso, el Recall para los ‚ÄúNo Response‚Äù es mayor que el Recall para los ‚ÄúResponse‚Äù. Si analizamos la representaci√≥n de cada clase en el dataset inicial, podemos ver que realmente existe una relaci√≥n entre los valores resultantes y la proporci√≥n de las clases. . . Con respecto a la curva ROC y el valor AUC, podemos decir que el modelo se comporta relativamente bien. El valor resultante del √°rea bajo la curva es de 0.861. Supera el valor de la elecci√≥n aleatoria, donde el √°rea ser√≠a de 0.5. . . Tomando en consideraci√≥n este mismo concepto de mejora sobre la selecci√≥n aleatoria, la confianza de predicci√≥n del modelo va a ser distinta para cada uno de los valores que clasifica. . A partir de esta informaci√≥n, centr√°ndonos en los verdaderos positivos, es posible construir un gr√°fico que muestre como var√≠a la mejora del modelo en funci√≥n de la confianza. . De esta manera, es posible saber la mejora sobre la elecci√≥n aleatoria, en definitiva, que tan bien funciona un modelo, tomando parte de la poblaci√≥n total. . En este caso encontr√© que la cobertura alcanza el 70% en la tercera barra del gr√°fico. Este dato es interesante porque significar√≠a que un 30% de la poblaci√≥n es necesaria para lograr un 70%. . .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/na%C3%AFve%20bayes/validaci%C3%B3n%20del%20modelo/roc/lift%20charts/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Naive-Bayes.html",
            "relUrl": "/na%C3%AFve%20bayes/validaci%C3%B3n%20del%20modelo/roc/lift%20charts/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Naive-Bayes.html",
            "date": " ‚Ä¢ Nov 28, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Caso de Estudio: Detecci√≥n de enfermedad card√≠aca",
            "content": "Contexto del problema . Me resulta particularmente interesante las posibilidades de aplicaci√≥n de la Ciencia de Datos en el √°rea de la Medicina. Los Hospitales y centros m√©dicos en general, son instituciones que generan y registran informaci√≥n sobre el estado de sus pacientes diariamente. Por lo que, en principio es un buen campo de investigaci√≥n para proyectos de esta √≠ndole. . . La informaci√≥n puede ser aprovechada mediante t√©cnicas de Machine Learning para el entrenamiento de modelos que aporten valor a la labor m√©dica. Sin embargo, la mayor√≠a de las instituciones no estar√°n dispuestas a compartir dicha informaci√≥n para proteger as√≠ la privacidad de sus usuarios. En definitiva, los pacientes depositan su confianza en estos centros m√©dicos y tienen el derecho leg√≠timo de que su informaci√≥n personal no sea filtrada. Este derecho se ve respaldado por la obligaci√≥n, del otro lado del mostrador, de resguardar esta informaci√≥n. Esto √∫ltimo deriva en que la disponibilidad de informaci√≥n sea mayormente escasa y dif√≠cil de conseguir. . En este caso de estudio se pretende analizar informaci√≥n de pacientes para la detecci√≥n de enfermedades card√≠acas. Se parte de Datasets que est√°n disponibles p√∫blicamente y han sido objeto de estudio en varios art√≠culos sobre esta tem√°tica. Estos datos provienen de 4 bases de datos distintas de: . Cleveland Clinic Foundation | Hungarian Institute of Cardiology, Budapest | V.A. Medical Center, Long Beach, CA | University Hospital, Zurich, Switzerland | El objetivo principal es demostrar las habilidades aprendidas considerando todas las etapas de un proyecto de Machine Learning. . Preparaci√≥n de los Datos . Primera aproximaci√≥n . A pesar de que los Datasets tienen or√≠genes distintos, los atributos que los componen se mantienen en todos los Datasets. Por lo tanto, podemos afirmar que una posible unificaci√≥n de los datos ser√° correcta y beneficiosa para el estudio, ya que contaremos con mayor cantidad de ejemplos y todos tienen la misma estructura. Esto implica tambi√©n, que los datos registrados est√©n en las mismas unidades y encodeados de la misma manera. Diversos tipos de datos pueden tener el mismo significado pero tener distinta representaci√≥n. Durante la preparaci√≥n de los datos, debemos prestar especial atenci√≥n a este aspecto ya que es uno de los errores m√°s frecuentes y es f√°cil pasar por alto. . Como primera aproximaci√≥n, deberemos investigar la estructura de los archivos, para luego poder levantarlos correctamente en la herramienta escogida. . Cada uno de los extractos de las bases de datos estan en archivos individuales .DATA. Existe adem√°s un archivo .NAMES que detalla la informaci√≥n presente en los anteriormente mencionados. . . La estructura de los datos no parece ser la m√°s conveniente para su lectura, por lo que surge la necesidad de realizar transformaciones de formato. Para ello, realizaremos un script que convierta cada Dataset a un archivo .csv independiente. . Reestructuraci√≥n de archivos de datos . Analizando la estructura de este archivo encuentro un patr√≥n, cada cierta cantidad de l√≠neas (En principio 10) hay una que finaliza la palabra ‚Äúname‚Äù. De acuerdo con el archivo ‚Äú.Names‚Äù asociado a estos Datasets, esta variable representa el √∫ltimo atributo del Dataset, por lo que podr√≠a ser utilizado para delimitar registros. En el caso de todos los valores intermedios, cada uno est√° asociado a un predictor seg√∫n el orden descripto en el archivo ‚Äú.Names‚Äù. . Vale destacar tambi√©n, que el primer valor de cada registro se ve incrementando secuencialmente y es distinto para cada uno de los grupos, por lo que coincide con la descripci√≥n de Identificador que se esperaba. Los identificadores son un tipo de datos que no debe ser incluido en el proceso de entrenamiento de un modelo. El mismo no aporta informaci√≥n relevante para el problema que se est√° analizando. La utilidad que aporta este dato es exclusivamente referencial, para que el lector pueda identificar registros en particular. . El script fue escrito en Javascript y ejecutado en un entorno local de NodeJS. A continuaci√≥n se presenta el c√≥digo utilizado para estandarizar la informaci√≥n en un formato legible y universal CSV. El script fue ejecutado para cada uno de los archivos del caso de estudio. Simplemente se leen los archivos en busca de la palabra clave ‚Äúname‚Äù, mientras que se van acumulando los valores obtenidos hasta el momento. Al encontrar esta palabra, se verifica la integridad del registro encontrado para decidir si ser√° considerado o no. Por √∫ltimo se escriben las l√≠neas en el archivo .csv de salida. . . Vale destacar que algunos ejemplos fueron retirados del Dataset final. Esto se debe a que conten√≠an caracteres inv√°lidos para los predictores que se est√°n manejando o la cantidad de datos superaba lo necesario por cada ejemplo. Esta t√©cnica supone una decisi√≥n sobre los datos, la cual debe ser tomada con precauci√≥n. En este caso, los ejemplos con problemas de encoding en el archivo fueron omitidos porque supon√≠an un porcentaje muy bajo de la muestra. . Dataset Ejemplos totales Ejemplos con errores Porcentaje de error . Cleveland | 290 | 8 | 2.75% | . Switzerland | 123 | 0 | 0% | . Hungarian | 294 | 0 | 0% | . Long Beach VA | 200 | 0 | 0% | . Ahora tenemos la informaci√≥n correctamente almacenada en 4 archivos CSV distintos. La siguiente imagen muestra el resultado de la ejecuci√≥n del script para el dataset ‚ÄúCleveland‚Äù. Tambi√©n es de utilidad incluir los encabezados de los datos. Los mismos est√°n disponibles en el archivo .Names. . . Unificaci√≥n de fuentes de datos . Para cargar el Dataset en Rapidminer, se agregar√°n las 4 fuentes de datos como archivos al repositorio local. Luego se recuperan en el flujo mediante el operador Retrieve. La idea es combinar estos datasets en un √∫nico dataset y analizar estad√≠sticas sobre √©l. Esto se puede realizar aplicando el operador Join. . . Lo primero que se puede apreciar es la gran cantidad de predictores, se dispone de un total de 76. Dentro de la etapa de prepraci√≥n de los datos tambi√©n es relevante reducir la cantidad de predictores a utilizar en el modelo. Esto supone un beneficio desde el punto de vista computacional, ya que se deber√° trabajar con datos dimensionalmente m√°s simples y por lo tanto con menos requerimientos de memoria y c√≥mputo. Por otra parte, algunos de estos predictores podr√≠an estar correlacionados entre s√≠, lo cual influye sustancialmente en la estabilidad de algunos modelos. Adem√°s de un beneficio, la cantidad de atributos puede ser una restricci√≥n para ciertos modelos como K-NN ya que por cada predictor que se agrega, el tiempo de ejecuci√≥n total aumenta exponencialmente. . An√°lisis de valores faltantes . Por otra parte, m√∫ltiples predictores contienen una gran cantidad de valores faltantes. Existen diversas t√©cnicas para combatir los valores faltantes de un dataset, conformando lo que se conoce como imputaci√≥n de valores. En este caso, usaremos el criterio de valores de faltantes en relaci√≥n al total de ejemplos para reducir los predictores a utilizar. Esto se debe a que ser√° muy dif√≠cil obtener imputaciones semejantes a la realidad cuando los valores faltantes predominan para ese predictor. . La decisi√≥n es eliminar aquellos predictores que tengan 33% o m√°s de valores faltantes. Para este caso, si el predictor tiene 300 o m√°s ejemplos con valores faltantes, ser√° directamente eliminado del Dataset. Analizando este criterio, los predictores a eliminar son estos: . Predictor # Valores Faltantes . slope | 308 | . cigs | 420 | . famhist | 422 | . rldv5 | 425 | . years | 432 | . thaltime | 453 | . thal | 477 | . diag | 558 | . ramus | 567 | . om2 | 572 | . cathef | 588 | . ca | 608 | . smoke | 669 | . thalsev | 769 | . junk | 780 | . dm | 804 | . thalpul | 898 | . restwm | 869 | . restef | 871 | . exerwm | 894 | . exeref | 897 | . earlobe | 898 | . exerckm | 898 | . restckm | 899 | . pncaden | 899 | . Esta operaci√≥n se puede realizar mediante el operador Select Attributes indicando manualmente los predictores a escoger. Esta decisi√≥n nos genera una nueva versi√≥n del Dataset con 45 Predictores para trabajar. Realmente ser√°n 44, porque debemos quitar el atributo ID antes de empezar a trabajar. Rapidminer ofrece dos opciones para este tipo de dato, se puede ajustar el rol del predictor a ‚ÄúID‚Äù o se puede directamente eliminar de la tabla. En este caso optar√© por eliminarlo ya que no aporta informaci√≥n importante de identificaci√≥n posterior. . El flujo hasta este punto se ve de esta manera: . . Imputaci√≥n de valores . Con respecto a los restantes valores faltantes, aplicaremos una imputaci√≥n cl√°sica utilizando utilizando K-NN. Este algoritmo basado en distancias, reemplazar√° los valores que falten recopilando informaci√≥n de ejemplos similares. Vale destacar que el funcionamiento de K-NN parte de la base de que los tipos de datos van a estar bien asignados. En este paso revisamos uno a uno los atributos para asegurarnos de que est√°n bien cargados. . Detecci√≥n de outliers . Tambi√©n es importante analizar la distribuci√≥n de valores para detectar posibles outliers. El primer paso en este an√°lisis es constatar errores de medici√≥n o registro de informaci√≥n. Esto se da en el atributo ‚ÄúProp‚Äù, donde deber√≠a existir una variable Binomial, se encuentra un ejemplo que tiene un valor de 22 para este predictor. Esto claremente se trata de outlier que no aporta informaci√≥n relevante al problema y solamente genera ruido. Tambi√©n sucede para la variable num√©rica ‚ÄúLmt‚Äù. Existe un valor de 162 que se encuentra muy alejado del resto de la distribuci√≥n. . En los siguientes gr√°ficos, en escala logar√≠tmica, se puede apreciar que solamente existe un registro con este valor outlier frente al resto de la distribuci√≥n. . . . Para este √∫ltimo caso fue necesario variar la cantidad de bins generadas por el histograma para visualizar el outlier. . Estos ejemplos con outliers ser√°n eliminados del Dataset . Los siguientes predictores tuvieron que ser ajustados en t√©rminos del tipo de dato: . Predictor Tipo de dato nuevo . dig | Binomial | . diuretic | Binomial | . exang | Binomial | . painloc | Binomial | . painexer | Binomial | . relrest | Binomial | . prop | Binomial | . nitr | Binomial | . htn | Binomial | . xhypo | Binomial | . pro | Binomial | . sex | Binomial | . num | Nominal | . restcg | Nominal | . cp | Nominal | . Feature selection . Para este caso, se ha decidido no utilizar t√©cnicas de Feature Selection avanzadas como An√°lisis de Componentes Lineales. Por el contrario, se seleccionar√°n los predictores cuya correlaci√≥n con la variable objetivo sea alta. Para ello, se definir√° un coeficiente de umbral para evaluar si un predictor ser√° utilizado, a partir de su valor de correlaci√≥n. Es importante entender que este filtro servir√° exclusivamente para predictores num√©ricos. El resto de los atributos permanecer√°n en el Dataset. . La correlaci√≥n con la variable de salida puede verse por medio de la matriz de correlaci√≥n. Tomando una correlaci√≥n de por lo menos 0.14, es decir mayor a 0.14 y menos a -0.14, el conjunto de predictores que cumplen esta condici√≥n es este: . thalach | age | thaldur | proto | chol | thalrest | oldpeak | laddist | ladprox | lvx4 | met | lmt | lfv | lvx3 | painexer | rcadist | tpeakbps | tpeakbpd | . Ahora que tenemos el conjunto final de predictores a utilizar, es pertinente evaluar las distintas distribuciones que puedan tener. Este dato es importante especialmente para ciertos algoritmos que tienen un mejor rendimiento con distribuciones gaussianas. Tambi√©n es una oportunidad para evaluar la proporci√≥n de clases de la variable objetivo. . Transformaciones sobre los datos . . Claramente la primera clase tiene una sobrerepresentaci√≥n en el Dataset. Los ejemplos que corresponden a esta clase son los pacientes cuya predicci√≥n indica que no sufrieron enfermedades card√≠acas. . En los predictores seleccionados de tipo continuo no se observa un sesgo o Skewness muy pronunciado en ning√∫n sentido. Por lo tanto, considero que los datos sin trasformaciones podr√≠an ser utilizados en primera instancia para evaluar distintos modelos. De ser necesario ajustar alguno de ellos, existen diversas t√©cnicas para transformar estos predictores. La ra√≠z cuadrada, el logaritmo natural y la funci√≥n inversa son probablemente las m√°s utilizadas para obtener distribuciones m√°s apropiadas, es decir, m√°s parecidas a la normal. . Modelo . Elecci√≥n del modelo . La generaci√≥n del modelo depende en gran parte del tipo de problema que estemos atacando, esto implica lo que queremos conseguir con el modelo y tambi√©n la naturaleza del problema. Para comenzar, estamos frente a un problema de clasificaci√≥n supervisada. Esto se debe a que cada ejemplo en nuestro Dataset est√° etiquetado con el valor de una variable objetivo dada. . El objetivo del modelo ser√° abstraer la relaci√≥n existente entre los datos de entrada y la salida a partir de los valores presentes en el Dataset. Adem√°s, estamos buscando ubicar los nuevos registros en cada una de las clases de la variable objetivo, que en este caso son 5 distintas, eso significa que estamos ante un problema de clasificaci√≥n multivariable. . Ante esta situaci√≥n, creo que una buena decisi√≥n ser√≠a comenzar con un √Årbol de Decisi√≥n. Luego de evaluar el modelo, optar√≠a por avanzar a un modelo de ensamble de Random Forest y revisar las m√©tricas con respecto al modelo anterior. . Separaci√≥n de datos para Entrenamiento y Test . El entrenamiento del modelo se realizar√° con una parte mayoritaria del Dataset. Esto implica una divisi√≥n donde una parte se utilizar√° en el entrenamiento y el resto de ejemplos para probar el modelo generado. En este caso, optar√© por seguir la regla del 70 / 30. La partici√≥n del Dataset puede ser realizada en Rapidminer mediante el operador ‚ÄúSplit Data‚Äù. . La selecci√≥n de ejemplos para cada una de las particiones debe tener un criterio, esta configuraci√≥n se conoce como Sampling Type. En principio se ofrecen varias opciones en el operador de Split, las m√°s recomendables son muestreo aleatorio y muestro estratificado. En este caso usaremos el estratificado para mantener la proporci√≥n de clases del Dataset original en estas nuevas particiones. . El flujo deber√≠a verse de la siguiente manera: . . El entrenamiento se realizar√° aplicando un K-Fold Cross Validation utilizando un valor de K est√°ndar de 10. Esta t√©cnica permite general un modelo m√°s realista, aprovechando la informaci√≥n que aporta el Dataset al m√°ximo. Esto se logra ejecutando distintas versiones del modelo y optimizando una m√©trica en particular. El proceso divide el dataset en K partes iguales y entrena usando K - 1 partes en cada iteraci√≥n. Asegurar la independencia de los datasets de test es un factor clave para el √©xito de esta t√©cnica. . Dentro del operador de Cross Validation, ubicamos el operador de √Årbol de decisi√≥n con los par√°metros por defecto. En principio esto servir√° para evaluar la performance general del modelo y encaminar una mejora del modelo utilizando este algoritmo de clasificaci√≥n. . El modelo deber√≠a verse de la siguiente manera: . . Evaluaci√≥n del √Årbol de Decisi√≥n . Los resultados preliminares de performance indican un rendimiento aceptable. El principal componente a analizar en esta fase preliminar es la Matriz de Confusi√≥n. Aqu√≠ se presentan las distintas clases a predecir y la correspondencia con los valores predichos. De esta tabla pueden obtenerse los falsos positivos, los falsos negativos, los verdaderos positivos y verdaderos negativos. En el caso ideal, todos los valores predichos corresponder√°n con los valores reales, el modelo tendr√° un 100% de precisi√≥n y tambi√©n la matriz de confusi√≥n tendr√° valores distintos de cero exclusivamente en la diagonal principal. . . Por medio de la matriz de confusi√≥n, se pueden obtener tambi√©n m√©tricas interesantes a analizar en un problema multiclase. La m√°s destacada se llama Class Recall la proporci√≥n de casos en que el modelo predijo bien esa clase en particular. Este dato resulta importante ya que nos indica el nivel de funcionamiento del modelo para una clase en particular. . En este caso de estudio, la variable objetivo tendr√° un valor entero entre 0 y 4, siendo las clases extremas las m√°s relevantes. Aquellos pacientes que tengan un 0 en la predicci√≥n, tendr√°n una probabilidad muy baja de tener una enfermedad card√≠aca. Lo contrario sucede para aquellos que obtienen 3 o 4, donde es muy importante que la situaci√≥n sea detectada para poder tratar y prevenir mayores consecuencias. . El peor Recall obtenido es para la clase 2 que est√© en medio, con un 16.28%. Sin embargo, esto no parecer√≠a ser tan cr√≠tico porque la mayor√≠a de las predicciones erradas dieron un resultado entre 1 y 3, valores no muy extremos que se encuentran en esa zona intermedia de riesgo. . Debemos recordar que al principio nos encontramos con un Dataset desbalanceado, exist√≠an muchos m√°s ejemplos de la clase 0 que de las dem√°s clases. Esto es peligroso al momento de validar un modelo porque sesga el resultado de Accuracy. Si el modelo clasifica todos los ejemplos como la clase predominante, el error de algunos ejemplos (las clases menos representadas) significar√°n poco con respecto al total. Una herramienta √∫til para estas situaciones es el balanceo por pesos, donde los registros del entrenamiento se ponderan seg√∫n la clase que tienen asignada. Este criterio de ponderaci√≥n busca igualar la representaci√≥n de clases en los ejemplos del Dataset. . Comparaci√≥n con Random Forest . La mayor parte de los modelos de producci√≥n utilizan un enfoque conocido como Ensambles. Esta t√©cnica tiene como objetivo reducir los errores de un modelo en particular con respecto a un dataset en particular. Es posible que la soluci√≥n encontrada aprenda demasiado de un Dataset y temrine asimilando el ruido de los datos como informaci√≥n √∫til. Si bien localmente puede que la soluci√≥n sea √∫til, no lo ser√° en la generalidad del espacio de posibilidades. Entonces, resulta √∫lil evaluar la opini√≥n que distintos modelos puedan tener para una predicci√≥n en particular. . De esta manera, se generan distintos algoritmos para elegir un resultado como respuesta, en base a las respuestas emitidas por los modelos individuales. Esto se puede generar de distintas maneras. Se podr√≠a tener una colecci√≥n de modelos variando las siguientes caracter√≠sticas: . Ejemplos para entrenamiento del modelo | Algoritmo del modelo | Par√°metros del modelo | Predictores del Dataset | . En este caso, aplicar√© un Random Forest para evaluar si el rendimiento general del modelo obtiene una mejora. Para ello, reemplazo el operador de √Årbol de decisi√≥n por el de Random Forest y configuro para que utilice un tama√±o de 1000 √°rboles y el criterio de votaci√≥n sea por confianza. . Estos son los resultados de la ejecuci√≥n de ese modelo: . . Como se puede ver en la matriz de confusi√≥n, los distintos Class Recall mejoraron bastante en comparaci√≥n con los resultados del √°rbol de decisi√≥n. Esto me aporta mayor confianza a la hora de utilizar este modelo de ensamble. . Tambi√©n vemos incrementada la precisi√≥n del modelo en general, ahora tenemos un 81.04%. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/caso%20de%20estudio/%C3%A1rbol%20de%20decisi%C3%B3n/random%20forest/rapidminer/preparaci%C3%B3n%20de%20los%20datos/entrenamiento/2021/11/25/Caso-de-Estudio-Predicci%C3%B3n-de-enfermedad-del-coraz%C3%B3n.html",
            "relUrl": "/caso%20de%20estudio/%C3%A1rbol%20de%20decisi%C3%B3n/random%20forest/rapidminer/preparaci%C3%B3n%20de%20los%20datos/entrenamiento/2021/11/25/Caso-de-Estudio-Predicci%C3%B3n-de-enfermedad-del-coraz%C3%B3n.html",
            "date": " ‚Ä¢ Nov 25, 2021"
        }
        
    
  
    
        ,"post4": {
            "title": "Estudio Del Efecto De La Estandarizaci√≥n Y Normalizaci√≥n",
            "content": "Efecto de la estandarizaci√≥n y normalizaci√≥n . En la mayor√≠a de los modelos de Machine Learning, es recomendable partir de datos estandarizados o normalizados para obtener un mejor desempe√±o del modelo a entrenar. Por esta raz√≥n, resulta interesante verificar el efecto de estas transformaciones previas en el resultado final del modelo. . Para evaluar emp√≠ricamente este efecto, se propone utilizar la herramienta Rapidminer y generar un flujo que valide la precisi√≥n de un modelo en particular. Para esto, el flujo deber√° verificar la m√©trica, a partir de un modelo entrenado con datos estandarizados (o normalizar) y otro con datos sin estandarizar (o normalizar). . El dataset a utilizar ser√° Wine UCI y el modelo a entrenar ser√° del tipo clasificador Naive Bayes. . A los efectos de entender mejor la problem√°tica, resulta conveniente explicitar la diferencia entre los conceptos ‚Äúnormalizaci√≥n‚Äù y ‚Äúestandarizaci√≥n‚Äù. Si bien ambas t√©cnicas implican llevar los predictores a una escala com√∫n, su implementaci√≥n es distinta. La normalizaci√≥n se centra en el intervalo objetivo de la transformaci√≥n, escalando los valores seg√∫n su proporci√≥n original (p.e.: El intervalo 0.0 a 1.1). Por otra parte, la estandarizaci√≥n implica llevar los valores de los atributos a un conjunto con media cero y desviaci√≥n est√°ndar uno. . Para comenzar se crea un nuevo flujo en Rapidminer y se agregan los operadores de Naive Bayes. Cada uno de los operadores se nutren con el modelo Wine UCI, con el detalle de que uno de ellos recibe los datos normalizados utilizando ‚ÄúTransformaci√≥n Z‚Äù en la configuraci√≥n del operador. . . El modelo por evaluar no deber√≠a ser afectado por las escalas de los atributos, ya que la base del algoritmo es la probabilidad condicional y no implica un c√°lculo de distancia. . Al ejecutar el flujo de Rapidminer se obtienen como salidas las siguientes matrices de confusi√≥n: . Modelo sin normalizaci√≥n . . Modelo normalizado . . Como conclusi√≥n, se verific√≥ para un caso particular, que la estandarizaci√≥n o normalizaci√≥n de los datos no impacta significativamente en la precisi√≥n de un modelo Naive Bayes. Esto condice con la teor√≠a mencionada anteriormente sobre la base del modelo. Sin embargo, existen diversos modelos de Machine Learning de clasificaci√≥n que requieren la normalizaci√≥n para funcionar correctamente, por lo que este experimento no es suficiente para descartar la t√©cnica de normalizaci√≥n en la preparaci√≥n de los datos. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/24/Estudio-del-efecto-de-la-estandarizaci%C3%B3n-y-normalizaci%C3%B3n.html",
            "relUrl": "/2021/11/24/Estudio-del-efecto-de-la-estandarizaci%C3%B3n-y-normalizaci%C3%B3n.html",
            "date": " ‚Ä¢ Nov 24, 2021"
        }
        
    
  
    
        ,"post5": {
            "title": "Support Vector Machines: Predicci√≥n de clase para coordenadas en espacio 2D",
            "content": "La clasificaci√≥n binaria es un problema recurrente en el √°mbito de los modelos supervisados de Machine Learning. Al existir exclusivamente dos clases, la visualizaci√≥n de los datos (Mayoritariamente en dos dimensiones) otorga la capacidad de decidir enfrentar con el problema con un tipo de algoritmos en particular. . En este art√≠culo se demostrar√° el uso de un algoritmo reciente para clasificaci√≥n binaria llamado ‚ÄúSupport Vector Machines‚Äù. El mismo recoge aspectos de la Estad√≠stica, la Teor√≠a Matem√°tica de la Optimizaci√≥n y de las Ciencias de la Computaci√≥n. . Contexto . Para este ejercicio se utilizar√° un Dataset de ejemplo de coordenadas bidimensionales en el plano. Cada una de ellas tendr√° una clase correspondiente, la cual ser√° la variable objetivo a predecir del modelo. El ejercicio fue extra√≠do del libro ‚ÄúPredictive Analytics and Data Mining‚Äù (Kotu, 2015). . Coordenada X1 [Num√©rica] | Coordenada X2 [Num√©rica] | Clase [Binomial (A - B)] | . El dataset es muy reducido, contiene solamente 17 ejemplos. Por tanto, entrenaremos un modelo de SVM utilizando la totalidad de los datos disponibles. Para testear utilizaremos puntos elegidos estrat√©gicamente que nos permitan valorar su desempe√±o. . Datos . El dataset a utilizar es el siguiente: . x1 x2 Clase . 1.5 | 2.5 | A | . 2 | 2 | A | . 1 | 2 | A | . 0.75 | 3 | A | . 2 | 1 | A | . 1.75 | 1.75 | A | . 2.75 | 0.75 | A | . 2.5 | 1.5 | A | . 0.5 | 6 | B | . 1.5 | 6 | B | . 2 | 5.5 | B | . 1 | 5.5 | B | . 1 | 6.5 | B | . 2 | 4.5 | B | . 1.75 | 5.25 | B | . 2.75 | 4.25 | B | . 2.5 | 5 | B | . Los datos a utilizar cumplen con los requisitos de SVM. Todos los predictores son num√©ricos y la variable objetivo es binaria. . Modelo . La implemententaci√≥n del modelo ser√° en Rapidminer. El primer paso ser√° preparar los datos y cargarlos con un operador Retrieve. Es bastante interesante aprovechar esta oportunidad y visualizar los datos mediantes un gr√°fico plot. . . Con este gr√°fico se identifica f√°cilmente la naturaleza de la clasificaci√≥n a realizar. Ambas clases se encuentran separadas apropiadamente por una ‚Äúrecta imaginaria‚Äù. . Al flujo se debe agregar el operador de Support Vector Machine (SVM) as√≠ como tambi√©n un Apply Model. Este √∫ltimo se nutrir√° de ejemplos generados manualmente, los cuales cargaremos en un dataset nuevo. . El flujo deber√≠a verse de la siguiente manera: . . Resultados . El nuevo dataset contiene tres ejemplos (X1, X2) para clasificar: (1.5, 1), (1.5, 4) y (2, 7). . Desde un an√°lisis gr√°fico, los puntos 1 y 3 son f√°cilmente ubicables en los sectores donde una √∫nica clase predomina, sin embargo el punto 2 est√° en medio de estas zonas, en una frontera donde la predicci√≥n se vuelve m√°s compleja. . Por esta raz√≥n, la confianza de predicci√≥n ser√° m√°s alta para los puntos 1 y 3, mientras que el punto 2 tendr√° una confianza m√°s equilibrada entre clases. . . En esta imagen se confirman nuestras suposiciones sobre el comportamiento del modelo. . Adicionalmente, vale la pena revisar los pesos generados por el modelo. Volviendo a la teor√≠a, estos representan los coeficientes de cada predictor para partir de hyperespacio usando hyperplanos. . .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/svm/rapidminer/2021/11/04/Support-Vector-Machines-Datos-de-prueba-con-Kernel-Lineal.html",
            "relUrl": "/svm/rapidminer/2021/11/04/Support-Vector-Machines-Datos-de-prueba-con-Kernel-Lineal.html",
            "date": " ‚Ä¢ Nov 4, 2021"
        }
        
    
  
    
        ,"post6": {
            "title": "An√°lisis Del Discriminante Lineal Utilizando Python Y Scikit",
            "content": "LDA utilizando Python y Scikit-learn . Los algoritmos lineales son de gran utilizar para atacar problemas relativamente sencillos, donde es notaria una relaci√≥n lineal entre los predictores y la variable objetivo. . En esta ocasi√≥n se utilizar√° el algoritmo de An√°lisis de Discriminante Lineal para un problema de clasificaci√≥n binaria. Para ello, se utilizar√° la librer√≠a de Scikit-learn de Python que provee m√©todos de entrenamiento para un modelo LDA. . Se cuenta con un Dataset simple de √∫nicamente dos variables: X e Y. Es importante destacar que la cantidad de ejemplos no es muy grande, hay solamente 20 registros. La clase por predecir tiene dos posibles valores 0 y 1. . Importar librer√≠as y lectura de Dataset . Para este proceso se utilizar√°n las librer√≠as de Scikit-learn, Matplotlib y Pandas. Para evitar complicaciones mayores acceder√© a un documento de Google Colab y escribir√© el c√≥digo Python en un Jupyter Notebook. . . ## . ## . Graficar Dataset en dos dimensiones . Al disponer de √∫nicamente dos variables, la linealidad del problema puede verse representada mediante un gr√°fico de tipo ‚ÄúPlot‚Äù de ambos predictores. Esto puede ser realizado mediante la librer√≠a Matplotlib, manipulando previamente las columnas al invocar el m√©todo de graficar. . . En el gr√°fico se ve claramente la separaci√≥n de ambas clases en dos grupos disjuntos. Por lo tanto, podemos asegurar que la utilizaci√≥n de un modelo lineal para trabajar este Dataset es apropiada. . Entrenamiento del modelo . Habiendo confirmado la disposici√≥n de las clases en el gr√°fico plot, el siguiente paso implicar entrenar un modelo LDA utilizando el Dataset. Para ello, primero es necesario separar los predictores de la variable objetivo. . . El m√©todo train_test_split permite generar cuatro conjuntos a partir del Dataset. Separa los datos en predictores y variable objetivo. Adem√°s, aparta algunos datos para utilizar como validaci√≥n del modelo. En este caso se utilizar√° el 25% (5 ejemplos) del Dataset para validaci√≥n. . . Para entrenar el modelo LDA se utilizan los m√©todos importados de scikit-learn. . . ## . Validaci√≥n del modelo . Para validar el entrenamiento del modelo, utilizaremos los ejemplos que mantuvimos fuera del entrenamiento. Es importante tener tambi√©n los valores reales de la variable objetivo para poder compararlos con las predicciones del modelo. . . Los resultados muestran que el modelo realiz√≥ una predicci√≥n correcta en todos los casos de validaci√≥n. Tambi√©n es de utilidad examinar la matriz de confusi√≥n de las pruebas. . Esto se puede realizar mediante el m√©todo confusion_matrix de Scikit-learn Metrics. . . Cada columna representa las predicciones que el modelo realiz√≥, mientras que las filas los valores reales tomados del Dataset de validaci√≥n. Si todos los valores de la matriz con ceros a excepci√≥n de la diagonal principal, el modelo habr√° funcionado perfectamente. En caso contrario nos encontraremos con falsos positivos o falsos negativos, situaciones donde el modelo realiz√≥ la predicci√≥n incorrecta. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/02/An%C3%A1lisis-del-Discriminante-Lineal-utilizando-Python-y-Scikit.html",
            "relUrl": "/2021/11/02/An%C3%A1lisis-del-Discriminante-Lineal-utilizando-Python-y-Scikit.html",
            "date": " ‚Ä¢ Nov 2, 2021"
        }
        
    
  
    
        ,"post7": {
            "title": "Preparaci√≥n De Datos En Python üêç",
            "content": "Preparaci√≥n de datos con Python . Actualmente existen m√∫ltiples herramientas que permiten una exploraci√≥n profunda sobre los datos iniciales, las cuales son de gran utilidad para el analista que decide comenzar con este proceso. Desde una planilla de c√°lculo como Microsoft Excel, hasta m√≥dulos especializados en herramientas productivas, existen diversos mecanismos para llevar a cabo la preparaci√≥n de los datos, teniendo como objetivo generar los insumos para un modelo de Machine Learning. . En esta ocasi√≥n, se pretende investigar los distintos mecanismos que dispone Python y las librer√≠as desarrolladas por la comunidad, para el an√°lisis y tratamiento de datos. . Todo el c√≥digo Python ser√° escrito en un Jupyter Notebook, aprovechando las facilidades que este tipo de documentos ofrece para la ejecuci√≥n de este. Adem√°s, utilizar√© la herramienta Google Colab, la cual resuelve las referencias a las librer√≠as de Python a utilizar autom√°ticamente. . Importar librer√≠as y lectura del Dataset . El primer paso consiste en importar todas las librer√≠as a utilizar durante el proyecto. . NumPy . | Pandas . | Seaborn . | MatPlotLib . | . Luego se debe leer el contenido del archivo ‚ÄúTitanic-Dataset.csv‚Äù. Al ejecutar el c√≥digo se puede visualizar una vista previa de los registros. Deber√≠a verse de esta manera: . . Visualizar Dataset . Por medio de las siguientes instrucciones es posible identificar las columnas con valores num√©ricos. El resto de los atributos son de tipo categ√≥rico. . . La generaci√≥n de gr√°ficos para visualizar el Dataset puede realizarse mediante la librer√≠a Seaborn. Para ejemplificar, es posible generar un gr√°fico que ilustre la tasa de sobrevivientes, partiendo de la clase y el sexo del individuo. . . ## . Valores faltantes e imputaci√≥n . Este Dataset presenta valores faltantes √∫nicamente en los atributos Age, Cabin y Embarked. Para verificar esto, se utiliza el siguiente c√≥digo: . . Como se puede ver en este conteo de valores faltantes, los atributos m√°s impactados son Age y Cabin. En el caso de edad, ser√° necesario aplicar una imputaci√≥n de valores, siendo este atributo importante en la predicci√≥n del modelo. Probablemente, los atributos Cabin y Embarked no impacten significativamente en el desempe√±o del modelo, por lo que se podr√≠a considerar eliminarlos. . La eliminaci√≥n de atributos se realiza con el siguiente c√≥digo. Adem√°s se eliminar√° el n√∫mero de ticket, el cual no aporta ninguna informaci√≥n para la predicci√≥n. . . . Para decidir el valor que ser√° imputado al atributo edad, es conveniente analizar la distribuci√≥n de este. Esto se puede realizar mediante la librer√≠a matplotlib. . . La distribuci√≥n observada es bastante centrada pero algo inclinada hacia un lado, por lo que una buena decisi√≥n ser√≠a imputar la edad utilizando la mediana de los datos. Esto se realiza mediante el siguiente c√≥digo: . . Al concluir este paso, tenemos asegurado que los datos no contienen datos faltantes. Por lo que ser√°n de mayor utilidad y precisi√≥n a la hora de entrenar el modelo. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/29/Preparaci%C3%B3n-de-datos-en-Python.html",
            "relUrl": "/2021/10/29/Preparaci%C3%B3n-de-datos-en-Python.html",
            "date": " ‚Ä¢ Oct 29, 2021"
        }
        
    
  
    
        ,"post8": {
            "title": "√Årboles De Decisi√≥n Para Problemas De Regresi√≥n, Housing Uci",
            "content": "Al igual que los problemas de clasificaci√≥n vistos en art√≠culos anteriores, los √°rboles de decisi√≥n son una herramienta muy intuitiva para atacar los problemas supervisados de regresi√≥n. En este tipo de problemas, el objetivo ser√° predecir el valor de una variable continua a partir de un modelo generado con predictores mayormente num√©ricos. . Los √°rboles de decisi√≥n est√°n dentro del grupo de Algoritmos No Lineales, los cuales hacen menos suposiciones acerca de la estructura de los datos y/o la naturaleza del problema. Tambi√©n cuentan con la ventaja de una mayor interpretabilidad del modelo generado. Un √°rbol de decisi√≥n se representa frecuentemente como un √°rbol binario donde cada nodo representa una condici√≥n a evaluar con respecto a un predictor en particular, y cada hoja alberga un posible valor de la variable de salida. Esta representaci√≥n permite una r√°pida evaluaci√≥n de un nuevo ejemplo para poder obtener la predicci√≥n con respecto al mismo. . Por tanto, la complejidad de los √°rboles de decisi√≥n radica en la configuraci√≥n de los par√°metros del modelo, los cuales permiten generar distintas versiones del √°rbol en base a los valores escogidos. . Criterio . | Profundidad m√°xima . | Confianza . | Ganancia m√≠nima . | M√≠nimo tama√±o de hoja . | Otros . | . Contexto . Para este ejercicio se utilizar√° un Dataset provisto por la Univeridad de California Irvine (UCI) de precios de inmuebles bajo el nombre de distribuci√≥n ‚ÄúHousing‚Äù. Este es un Dataset cl√°sico utilizado en problemas de regresi√≥n, donde se intenta predecir la mediana de casas ocupadas por los due√±os. . Datos . El mismo cuenta con 12 predictores num√©ricos continuos y 1 binomial. Los atributos del dataset son los siguientes: . CRIM ‚Äì Proporci√≥n de crimen per c√°pita . | ZN ‚Äì Proporci√≥n de terreno residencial ubicado en solares mayors a 25.000 metros cuadrados. . | INDUS ‚Äì Proporci√≥n de acres de negocios no-retail por pueblo . | CHAS ‚Äì Contacto con el r√≠o Charles { S√≠, No} . | NOX ‚Äì Concentraci√≥n de √≥xido n√≠trico . | RM ‚Äì N√∫mero promedio de habitacione . | AGE ‚Äì Proporcion de unidades ocupadas por due√±os que fueron construidas antes de 1940 . | DIS ‚Äì Distancias ponderadas a 5 Centros de empleo de Boston . | RAD ‚Äì √çndice de accesibilidad a autopistas perif√©ricas . | TAX ‚Äì Proporci√≥n de impuestos del valor total por cada 10000 USD . | PTRATIO ‚Äì Proporci√≥n de Profesor y Estudiantes en pueblo . | B - Proporci√≥n de gente negra . | LSTAT ‚Äì Porcentaje de estatus m√°s bajo de la poblaci√≥n . | . El Dataset comprende 506 valores √∫nicos y se encuentra totalmente completo, es decir ning√∫n predictor contiene valores faltantes. . Modelo . Tras analizar la completitud y buen estado de los datos, se debe implementar el modelo y analizar sus resultados. Para ello, har√© un flujo nuevo en Rapidminer que utilice el operador de √Årbol de decisi√≥n. A partir del Dataset ‚ÄúHousing‚Äù, generar√© dos conjuntos seg√∫n la regla 70/30. El primero ser√° destinado a entrenamiento y el segundo a testing del modelo. . Adem√°s, utilizar√© en esta ocasi√≥n un K-Fold Cross Validation para obtener un resultado m√°s realista con respecto a este Dataset que es de un tama√±o reducido. Este operador nos permitir√° dividir el Dataset en K particiones o ‚ÄúFolds‚Äù, entrenar K modelos distintos, reservando cada una de esas particiones para test en cada iteraci√≥n. . El flujo en Rapidminer se deber√≠a ver de la siguiente manera: . . . Al ejecutar este modelo, Rapidminer obtenemos como resultados como la visualizaci√≥n del √°rbol generado que podr√° darnos m√°s informaci√≥n sobre el ajuste de los par√°metros. Tambi√©n el vector de Performance indicando los valores de Ra√≠z cuadrada del error medio (RMSE), el error absoluto y el error medio de predicci√≥n. . Se analizaron distintos valores de hyperpar√°metros para el √°rbol de decisi√≥n de regresi√≥n para obtener distintos resultados. . A continuaci√≥n, se registran los mejores valores encontrados por m√©todo de tanteo y observaci√≥n. . Profundidad Mejora m√≠nima Tama√±o de hoja m√≠nimo Alternativas de prepruning RMSE Error absoluto Error relativo . 10 | 0.01 | 5 | 10 | 4.795 | 3.009 +/- 3.734 | 14.11% +/- 14.90% | .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/18/%C3%81rboles-de-Decisi%C3%B3n-para-problemas-de-regresi%C3%B3n,-Housing-UCI.html",
            "relUrl": "/2021/10/18/%C3%81rboles-de-Decisi%C3%B3n-para-problemas-de-regresi%C3%B3n,-Housing-UCI.html",
            "date": " ‚Ä¢ Oct 18, 2021"
        }
        
    
  
    
        ,"post9": {
            "title": "Direccionamiento De Una Campa√±a De Marketing Para Ereaders",
            "content": "En m√∫ltiples ocasiones, los equipos de marketing deber√°n estimar la mejor estrategia para vender un nuevo producto. Especialmente cuando se trata de una marca establecida, direccionar la estrategia para los clientes potenciales determina el √©xito del lanzamiento del producto. Estos casos son especiales, ya que es muy alta la probabilidad de que se disponga de datos sobre los productos anteriormente lanzados. . En base a datos hist√≥ricos, es posible entrenar un modelo que permita determinar si un cliente comprar√° el nuevo producto cuando este sea anunciado. En este caso, se estudiar√° un Dataset con informaci√≥n de los patrones de comportamiento de los clientes en sus actividades en el sitio web de una empresa de E-Readers. . Contexto . Se dispone de dos Dataset con informaci√≥n de los clientes. Uno de ellos est√° completamente etiquedado de acuerdo con las compras realizadas de los clientes. La variable objetivo a predecir es del tipo nominal, por lo que tiene m√∫ltiples y determinados valores posibles. . Por su parte, el segundo Dataset no contiene esta variable, el mismo corresponde a informaci√≥n actual de los perfiles de los clientes. A partir de √©ste, se deber√°n predecir las clases en la etapa de testeo del modelo. . Naturalmente este tipo de problema se tratar√° con un modelo supervisado de clasificaci√≥n, ya que es de nuestro inter√©s predecir la clase de clientes sin clasificar. . Para este ejercicio, se utilizar√° un modelo de √Årbol de Decisi√≥n en Rapidminer. El objetivo ser√° examinar y comparar el funcionamiento de este tipo de algoritmo no lineal para un ejercicio de clasificaci√≥n. . Datos . Los √°rboles de decisi√≥n son modelos de Machine Learning que requieren poca preparaci√≥n de los datos, ya que son bastantes permisivos con valores faltantes, distribuciones sesgadas y distintos tipos de datos. . Con respecto a este √∫ltimo punto, la siguiente tabla muestra informaci√≥n sobre los predictores disponibles: . Predictor Rango Comentario . ID | - | Identificador del cliente | . Edad | - | Variable num√©rica | . EstadoCivil | C - S | Variable binomial | . Sexo | F ‚Äì M | Variable binomial | . ActividadWebsite | Escasa ‚Äì Regular - Frecuente | Variable nominal | . ComproElectronicos12 | SI ‚Äì NO | Variable binomial | . MiroElectronicos12 | SI ‚Äì NO | Variable binomial | . ComproMedios18 | SI ‚Äì NO | Variable binomial | . ComproLibrosDigitales | SI - NO | Variable binomial | . MetodoPago | Transferencia Bancaria ‚Äì Cuenta Website ‚Äì Tarjeta Credito ‚Äì Debito Mensual | Variable nominal | . En este caso, la mayor√≠a de variables son categ√≥ricas. Considero que todos los datos proporcionados son relevantes para el ejercicio, a excepci√≥n del identificador del cliente. Este dato no es de utilidad para la predicci√≥n, ya que se trata de una referencia a un registro en particular. . Este tipo de datos puede ser excluido del Dataset desde el inicio. Sin embargo, en este caso usar√© una ventaja que aporta Rapidminer, cambiar√© el tipo de dato a ‚ÄúIdentificador‚Äù. De esta manera, se mantendr√° a lo largo del flujo, pero no influir√° en el entrenamiento del modelo. . . Por medio del operador ‚ÄúSet Role‚Äù es posible modificar el papel de ese atributo en Rapidminer. En la siguiente imagen se puede ver como son diferenciados de los dem√°s. . . Modelo . Agregamos un operador de √Årbol de Decisi√≥n en el flujo de Rapidminer. El mismo usar√° el dataset de entrenamiento como entrada. El modelo resultante ser√° probado mediante el operador ‚ÄúApply Model‚Äù, usando el Dataset de Test. . El flujo resultante se ve de la siguiente manera: . . Al ejecutar el modelo con los datos de prueba, vemos que Rapidminer agrega 4 atributos de confianza y un atributo adicional para la predicci√≥n de la clase objetivo. . Cada una de estas confianzas indican que tan probable es que el modelo clasifique el registro en cada una de las 4 clases. Por tanto, la suma de todas las confianzas da como resultado 1. . . La probabilidad obtenida para cada registro corresponde a la proporci√≥n de ejemplos de clases distintas que durante el entrenamiento se generaron en el mismo nodo hoja. . Queda claro que aquellos registros con confianzas m√°s equilibrados tienen menor seguridad de predicci√≥n frente a aquellos donde las diferencias son marcadas. . A continuaci√≥n, voy a seleccionar 3 registros en particular y aplicar modificaciones en los hyperpar√°metros del √°rbol de decisi√≥n. Esta prueba deber√≠a arrojar resultados distintos de clase objetivo, especialmente si los registros elegidos tienen confianzas equilibradas. . Se ejecutar√°n 4 configuraciones distintas con los siguientes valores de par√°metros . Criterio: Gain_Ratio Maximal_Depth: 10 Minimal_Gain: 0.01 . | Criterio: Gini_Index Maximal_Depth: 10 Minimal_Gain: 0.01 . | Criterio: Gain_Ratio Maximal_Depth: 5 Minimal_Gain: 0.05 . | Criterio: Gain_Ratio Maximal_Depth: 20 Minimal_Gain: 0.05 . | ID Cliente Predicci√≥n Test 1 Predicci√≥n Test 2 Predicci√≥n Test 3 Predicci√≥n Test 4 . 98200 | Adoptante Temprano 54% | Adoptante Temprano 100% | Adoptante Temprano 41% | MayoriaTardia 84% | . 76655 | MayoriaTardia 84% | Adoptante Temprano 50% | MayoriaTardia 75% | Adoptante Temprano 100% | . 63570 | Adoptante Temprano 100% | Adoptante Temprano 75% | Adoptante Temprano 100% | Adoptante Temprano 100% | . Como conlusi√≥n, los par√°metros que establecen las distintas operaciones a efectuar sobre el √°rbol de decisi√≥n generan resultados muy distintos entre s√≠, cambiando la confianza de predicci√≥n de algunos registros, incluso la clase predicha en s√≠. . Este tipo de algoritmo de Machine Learning es f√°cil de entender, ya que su salida es una representaci√≥n que podemos entender. El modelo genera un √°rbol donde en cada nodo se deber√° tomar una decisi√≥n con respecto a un predictor dado y en sus hojas estar√°n las clases objetivo a predecir. Por tanto, predecir un nuevo valor implica simplemente recorrer el √°rbol generado. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/16/Direccionamiento-de-una-campa%C3%B1a-de-marketing-para-eReaders.html",
            "relUrl": "/2021/10/16/Direccionamiento-de-una-campa%C3%B1a-de-marketing-para-eReaders.html",
            "date": " ‚Ä¢ Oct 16, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "Sobre mi",
          "content": "Soy Ignacio Mart√≠nez, un estudiante avanzado de Ingenier√≠a en Inform√°tica con un inter√©s particular por las nuevas tecnolog√≠as. En este portafolio pretendo publicar todos mis trabajos significativos realizados en el √°rea del Aprendizaje Autom√°tico. . Trabajo a tiempo parcial como Analista en Sistemas, tengo experiencia en Desarrollo Web, Business Intelligence e intregraciones por API. . Puedes encontrar el resto de mis trabajos en Github. .",
          "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ ‚Äúsitemap.xml‚Äù | absolute_url }} | .",
          "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}