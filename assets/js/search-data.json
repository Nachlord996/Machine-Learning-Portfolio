{
  
    
        "post0": {
            "title": "Respuesta A Una Campaña De Mail Usando Naïve Bayes",
            "content": "Validación de un modelo: Respuesta a una campaña de mail usando Naïve Bayes . La calidad de un modelo de Machine Learning no se evalúa exclusivamente con los resultados que este genera durante su entrenamiento y validación. La aplicabilidad de cualquier modelo debe considerar múltiples métricas que demuestren su efectividad en la realidad. . Evaluar incorrectamente un modelo podría generar expectativas irrealistas de su funcionamiento, las cuales harán aparecer problemas en la fase de producción, al utilizar el modelo con datos de la realidad. . Por tanto, el desempeño real de un modelo podría no ser aceptable y en muchos casos generar daños elevados para los clientes, incluyendo dinero y vidas. . Un error frecuente de los analistas, es sobredimensionar el funcionamiento de un modelo en base al porcentaje de precisión que arroje. El objetivo de este documento será evaluar distintas técnicas de validación de modelos de Machine Learning para un caso particular. . Escenario . Para este caso, utilizaremos la herramienta de Rapidminer para generar datos de ejemplo. El objetivo es predecir si una persona responderá a una campaña de marketing por mail utilizando atributos demográficos. . Para ello, existe un operador en Rapidminer “Generate Direct Mailing Data”. Este operador utiliza dos parámetros: . Número de ejemplos a generar. En este caso usaré 10000. . | Semilla local. Activar este parámetro me permitirá repetir el ejercicio manteniendo los datos generados. . | . Preparación de Datos . El operador de generación arroja un dataset del tamaño indicado con los siguientes predictores: . Nombre . | Edad . | Estilo de vida (Tres categorías: Activo, Cómodo o Saludable) . | Código Postal . | Estado Civil . | Tipo de vehículo (Dos categorías: Práctico o Costoso) . | Deporte (Tres deportes distintos: Bádminton, Fútbol y Atletismo) . | Salario . | Respuesta al mail . | . Antes de comenzar a trabajar, fue necesario realizar algunos ajustes. En primer lugar, la variable a predecir (Si la persona realmente responderá a la campaña por mail) tiene dos posibles valores Response / No Responde, por lo que se puede tratar esta variable como Binomial. . El dataset completo está etiquetado, por lo que podremos dividirlo en dos para separar en Entrenamiento y Test. Aplicaremos la regla del 80/20 y además configuraremos un Split Validation para el dataset de entrenamiento. . En este caso, la validación tendrá una proporción 70/30. El flujo resultante es el siguiente: . . Modelo . Al enfrentarnos a un problema supervisado de clasificación binaria, disponemos de una gran variedad de modelos para probar. Sin embargo, como el objetivo es analizar las métricas de Performance, optaremos por un modelo sencillo de Naive Bayes sin pensar mucho en cuál será el más adecuado. . Dentro del operador de Split Validation, ubiqué el operador de Naive Bayes, aplicación del modelo y luego un operador de Performance activando las siguientes opciones: . Accuracy . | False positive . | False negative . | True positive . | True negative . | Sensivity . | Specificity . | AUC . | . Por último, utilicé el dataset reservado como Hold-out para testear el modelo generado. A nivel principal del flujo, se debe agregar un operador de Apply Model con el Dataset de test. . Como última medida de performance, agregué una Lift Chart a la salida del Apply Model. Este gráfico apuntará al valor de la clase a predecir “Response”. . ## . Resultados . El proceso de Rapidminer genera la siguiente matriz de confusión para los resultados del dataset de entrenamiento: .   Response reales No Response reales . Response Predichos | 56 | 33 | . No Response Predichos | 15 | 136 | . Si tomamos como clase positiva a los valores “Response”, obtendremos los siguientes datos: . Falsos positivos (FP): 33 . | Falsos negativos (FN): 15 . | Verdaderos positivos (TP): 56 . | Verdaderos negativos (TN): 136 . | . Para estos valores, podemos verificar las métricas teóricas y contrastarlas con los resultados de Rapidminer. . Sensibilidad: TP / (TP + FN) . 56 / (56 + 15) = 56 / 71 = 0.788 =&gt; 78.8% . Especificidad: TN / (TN + FP) . 136 / (136 + 33) = 136 / 169 = 0.804 = 80.4% . Estos valores son idénticos a los calculados automáticamente por Rapidminer: . . Resulta interesante analizar los valores de Class Recall. Puntualmente, estos valores representan la proporción en que una clase dada de los datos fue predicha correctamente. . Este valor tiende a ser influenciado por la representación de la clase en el Dataset. Es decir, el modelo podrá comportarse adecuadamente en general, pero muy deficientemente para una clase en particular. Este efecto se maximiza cuando otras clases están sobrerepresentadas en el Dataset. Cuando esto sucede, se dice que el Dataset está desbalanceado. . En este caso, el Recall para los “No Response” es mayor que el Recall para los “Response”. Si analizamos la representación de cada clase en el dataset inicial, podemos ver que realmente existe una relación entre los valores resultantes y la proporción de las clases. . . Con respecto a la curva ROC y el valor AUC, podemos decir que el modelo se comporta relativamente bien. El valor resultante del área bajo la curva es de 0.861. Supera el valor de la elección aleatoria, donde el área sería de 0.5. . . Tomando en consideración este mismo concepto de mejora sobre la selección aleatoria, la confianza de predicción del modelo va a ser distinta para cada uno de los valores que clasifica. . A partir de esta información, centrándonos en los verdaderos positivos, es posible construir un gráfico que muestre como varía la mejora del modelo en función de la confianza. . De esta manera, es posible saber la mejora sobre la elección aleatoria, en definitiva, que tan bien funciona un modelo, tomando parte de la población total. . En este caso encontré que la cobertura alcanza el 70% en la tercera barra del gráfico. Este dato es interesante porque significaría que un 30% de la población es necesaria para lograr un 70%. . .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Na%C3%AFve-Bayes.html",
            "relUrl": "/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Na%C3%AFve-Bayes.html",
            "date": " • Nov 28, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "Árboles De Decisión Para Problemas De Regresión, Housing Uci",
            "content": "Al igual que los problemas de clasificación vistos en artículos anteriores, los árboles de decisión son una herramienta muy intuitiva para atacar los problemas supervisados de regresión. En este tipo de problemas, el objetivo será predecir el valor de una variable continua a partir de un modelo generado con predictores mayormente numéricos. . Los árboles de decisión están dentro del grupo de Algoritmos No Lineales, los cuales hacen menos suposiciones acerca de la estructura de los datos y/o la naturaleza del problema. También cuentan con la ventaja de una mayor interpretabilidad del modelo generado. Un árbol de decisión se representa frecuentemente como un árbol binario donde cada nodo representa una condición a evaluar con respecto a un predictor en particular, y cada hoja alberga un posible valor de la variable de salida. Esta representación permite una rápida evaluación de un nuevo ejemplo para poder obtener la predicción con respecto al mismo. . Por tanto, la complejidad de los árboles de decisión radica en la configuración de los parámetros del modelo, los cuales permiten generar distintas versiones del árbol en base a los valores escogidos. . Criterio . | Profundidad máxima . | Confianza . | Ganancia mínima . | Mínimo tamaño de hoja . | Otros . | . Contexto . Para este ejercicio se utilizará un Dataset provisto por la Univeridad de California Irvine (UCI) de precios de inmuebles bajo el nombre de distribución “Housing”. Este es un Dataset clásico utilizado en problemas de regresión, donde se intenta predecir la mediana de casas ocupadas por los dueños. . Datos . El mismo cuenta con 12 predictores numéricos continuos y 1 binomial. Los atributos del dataset son los siguientes: . CRIM – Proporción de crimen per cápita . | ZN – Proporción de terreno residencial ubicado en solares mayors a 25.000 metros cuadrados. . | INDUS – Proporción de acres de negocios no-retail por pueblo . | CHAS – Contacto con el río Charles { Sí, No} . | NOX – Concentración de óxido nítrico . | RM – Número promedio de habitacione . | AGE – Proporcion de unidades ocupadas por dueños que fueron construidas antes de 1940 . | DIS – Distancias ponderadas a 5 Centros de empleo de Boston . | RAD – Índice de accesibilidad a autopistas periféricas . | TAX – Proporción de impuestos del valor total por cada 10000 USD . | PTRATIO – Proporción de Profesor y Estudiantes en pueblo . | B - Proporción de gente negra . | LSTAT – Porcentaje de estatus más bajo de la población . | . El Dataset comprende 506 valores únicos y se encuentra totalmente completo, es decir ningún predictor contiene valores faltantes. . Modelo . Tras analizar la completitud y buen estado de los datos, se debe implementar el modelo y analizar sus resultados. Para ello, haré un flujo nuevo en Rapidminer que utilice el operador de Árbol de decisión. A partir del Dataset “Housing”, generaré dos conjuntos según la regla 70/30. El primero será destinado a entrenamiento y el segundo a testing del modelo. . Además, utilizaré en esta ocasión un K-Fold Cross Validation para obtener un resultado más realista con respecto a este Dataset que es de un tamaño reducido. Este operador nos permitirá dividir el Dataset en K particiones o “Folds”, entrenar K modelos distintos, reservando cada una de esas particiones para test en cada iteración. . El flujo en Rapidminer se debería ver de la siguiente manera: . . . Al ejecutar este modelo, Rapidminer obtenemos como resultados como la visualización del árbol generado que podrá darnos más información sobre el ajuste de los parámetros. También el vector de Performance indicando los valores de Raíz cuadrada del error medio (RMSE), el error absoluto y el error medio de predicción. . Se analizaron distintos valores de hyperparámetros para el árbol de decisión de regresión para obtener distintos resultados. . A continuación, se registran los mejores valores encontrados por método de tanteo y observación. . Profundidad Mejora mínima Tamaño de hoja mínimo Alternativas de prepruning RMSE Error absoluto Error relativo . 10 | 0.01 | 5 | 10 | 4.795 | 3.009 +/- 3.734 | 14.11% +/- 14.90% | .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/18/%C3%81rboles-de-Decisi%C3%B3n-para-problemas-de-regresi%C3%B3n,-Housing-UCI.html",
            "relUrl": "/2021/10/18/%C3%81rboles-de-Decisi%C3%B3n-para-problemas-de-regresi%C3%B3n,-Housing-UCI.html",
            "date": " • Oct 18, 2021"
        }
        
    
  
    
        ,"post2": {
            "title": "Direccionamiento De Una Campaña De Marketing Para Ereaders",
            "content": "En múltiples ocasiones, los equipos de marketing deberán estimar la mejor estrategia para vender un nuevo producto. Especialmente cuando se trata de una marca establecida, direccionar la estrategia para los clientes potenciales determina el éxito del lanzamiento del producto. Estos casos son especiales, ya que es muy alta la probabilidad de que se disponga de datos sobre los productos anteriormente lanzados. . En base a datos históricos, es posible entrenar un modelo que permita determinar si un cliente comprará el nuevo producto cuando este sea anunciado. En este caso, se estudiará un Dataset con información de los patrones de comportamiento de los clientes en sus actividades en el sitio web de una empresa de E-Readers. . Contexto . Se dispone de dos Dataset con información de los clientes. Uno de ellos está completamente etiquedado de acuerdo con las compras realizadas de los clientes. La variable objetivo a predecir es del tipo nominal, por lo que tiene múltiples y determinados valores posibles. . Por su parte, el segundo Dataset no contiene esta variable, el mismo corresponde a información actual de los perfiles de los clientes. A partir de éste, se deberán predecir las clases en la etapa de testeo del modelo. . Naturalmente este tipo de problema se tratará con un modelo supervisado de clasificación, ya que es de nuestro interés predecir la clase de clientes sin clasificar. . Para este ejercicio, se utilizará un modelo de Árbol de Decisión en Rapidminer. El objetivo será examinar y comparar el funcionamiento de este tipo de algoritmo no lineal para un ejercicio de clasificación. . Datos . Los árboles de decisión son modelos de Machine Learning que requieren poca preparación de los datos, ya que son bastantes permisivos con valores faltantes, distribuciones sesgadas y distintos tipos de datos. . Con respecto a este último punto, la siguiente tabla muestra información sobre los predictores disponibles: . Predictor Rango Comentario . ID | - | Identificador del cliente | . Edad | - | Variable numérica | . EstadoCivil | C - S | Variable binomial | . Sexo | F – M | Variable binomial | . ActividadWebsite | Escasa – Regular - Frecuente | Variable nominal | . ComproElectronicos12 | SI – NO | Variable binomial | . MiroElectronicos12 | SI – NO | Variable binomial | . ComproMedios18 | SI – NO | Variable binomial | . ComproLibrosDigitales | SI - NO | Variable binomial | . MetodoPago | Transferencia Bancaria – Cuenta Website – Tarjeta Credito – Debito Mensual | Variable nominal | . En este caso, la mayoría de variables son categóricas. Considero que todos los datos proporcionados son relevantes para el ejercicio, a excepción del identificador del cliente. Este dato no es de utilidad para la predicción, ya que se trata de una referencia a un registro en particular. . Este tipo de datos puede ser excluido del Dataset desde el inicio. Sin embargo, en este caso usaré una ventaja que aporta Rapidminer, cambiaré el tipo de dato a “Identificador”. De esta manera, se mantendrá a lo largo del flujo, pero no influirá en el entrenamiento del modelo. . . Por medio del operador “Set Role” es posible modificar el papel de ese atributo en Rapidminer. En la siguiente imagen se puede ver como son diferenciados de los demás. . . Modelo . Agregamos un operador de Árbol de Decisión en el flujo de Rapidminer. El mismo usará el dataset de entrenamiento como entrada. El modelo resultante será probado mediante el operador “Apply Model”, usando el Dataset de Test. . El flujo resultante se ve de la siguiente manera: . . Al ejecutar el modelo con los datos de prueba, vemos que Rapidminer agrega 4 atributos de confianza y un atributo adicional para la predicción de la clase objetivo. . Cada una de estas confianzas indican que tan probable es que el modelo clasifique el registro en cada una de las 4 clases. Por tanto, la suma de todas las confianzas da como resultado 1. . . La probabilidad obtenida para cada registro corresponde a la proporción de ejemplos de clases distintas que durante el entrenamiento se generaron en el mismo nodo hoja. . Queda claro que aquellos registros con confianzas más equilibrados tienen menor seguridad de predicción frente a aquellos donde las diferencias son marcadas. . A continuación, voy a seleccionar 3 registros en particular y aplicar modificaciones en los hyperparámetros del árbol de decisión. Esta prueba debería arrojar resultados distintos de clase objetivo, especialmente si los registros elegidos tienen confianzas equilibradas. . Se ejecutarán 4 configuraciones distintas con los siguientes valores de parámetros . Criterio: Gain_Ratio Maximal_Depth: 10 Minimal_Gain: 0.01 . | Criterio: Gini_Index Maximal_Depth: 10 Minimal_Gain: 0.01 . | Criterio: Gain_Ratio Maximal_Depth: 5 Minimal_Gain: 0.05 . | Criterio: Gain_Ratio Maximal_Depth: 20 Minimal_Gain: 0.05 . | ID Cliente Predicción Test 1 Predicción Test 2 Predicción Test 3 Predicción Test 4 . 98200 | Adoptante Temprano 54% | Adoptante Temprano 100% | Adoptante Temprano 41% | MayoriaTardia 84% | . 76655 | MayoriaTardia 84% | Adoptante Temprano 50% | MayoriaTardia 75% | Adoptante Temprano 100% | . 63570 | Adoptante Temprano 100% | Adoptante Temprano 75% | Adoptante Temprano 100% | Adoptante Temprano 100% | . Como conlusión, los parámetros que establecen las distintas operaciones a efectuar sobre el árbol de decisión generan resultados muy distintos entre sí, cambiando la confianza de predicción de algunos registros, incluso la clase predicha en sí. . Este tipo de algoritmo de Machine Learning es fácil de entender, ya que su salida es una representación que podemos entender. El modelo genera un árbol donde en cada nodo se deberá tomar una decisión con respecto a un predictor dado y en sus hojas estarán las clases objetivo a predecir. Por tanto, predecir un nuevo valor implica simplemente recorrer el árbol generado. .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/2021/10/16/Direccionamiento-de-una-campa%C3%B1a-de-marketing-para-eReaders.html",
            "relUrl": "/2021/10/16/Direccionamiento-de-una-campa%C3%B1a-de-marketing-para-eReaders.html",
            "date": " • Oct 16, 2021"
        }
        
    
  
    
        ,"post3": {
            "title": "Fastpages Notebook Blog Post",
            "content": "About . This notebook is a demonstration of some of capabilities of fastpages with notebooks. . With fastpages you can save your jupyter notebooks into the _notebooks folder at the root of your repository, and they will be automatically be converted to Jekyll compliant blog posts! . Front Matter . The first cell in your Jupyter Notebook or markdown blog post contains front matter. Front matter is metadata that can turn on/off options in your Notebook. It is formatted like this: . # &quot;My Title&quot; &gt; &quot;Awesome summary&quot; - toc:true- branch: master - badges: true - comments: true - author: Hamel Husain &amp; Jeremy Howard - categories: [fastpages, jupyter] . Setting toc: true will automatically generate a table of contents | Setting badges: true will automatically include GitHub and Google Colab links to your notebook. | Setting comments: true will enable commenting on your blog post, powered by utterances. | . The title and description need to be enclosed in double quotes only if they include special characters such as a colon. More details and options for front matter can be viewed on the front matter section of the README. . Markdown Shortcuts . A #hide comment at the top of any code cell will hide both the input and output of that cell in your blog post. . A #hide_input comment at the top of any code cell will only hide the input of that cell. . The comment #hide_input was used to hide the code that produced this. . put a #collapse-hide flag at the top of any cell if you want to hide that cell by default, but give the reader the option to show it: . import pandas as pd import altair as alt . . put a #collapse-show flag at the top of any cell if you want to show that cell by default, but give the reader the option to hide it: . cars = &#39;https://vega.github.io/vega-datasets/data/cars.json&#39; movies = &#39;https://vega.github.io/vega-datasets/data/movies.json&#39; sp500 = &#39;https://vega.github.io/vega-datasets/data/sp500.csv&#39; stocks = &#39;https://vega.github.io/vega-datasets/data/stocks.csv&#39; flights = &#39;https://vega.github.io/vega-datasets/data/flights-5k.json&#39; . . place a #collapse-output flag at the top of any cell if you want to put the output under a collapsable element that is closed by default, but give the reader the option to open it: . print(&#39;The comment #collapse-output was used to collapse the output of this cell by default but you can expand it.&#39;) . The comment #collapse-output was used to collapse the output of this cell by default but you can expand it. . . Interactive Charts With Altair . Charts made with Altair remain interactive. Example charts taken from this repo, specifically this notebook. . Example 1: DropDown . # use specific hard-wired values as the initial selected values selection = alt.selection_single( name=&#39;Select&#39;, fields=[&#39;Major_Genre&#39;, &#39;MPAA_Rating&#39;], init={&#39;Major_Genre&#39;: &#39;Drama&#39;, &#39;MPAA_Rating&#39;: &#39;R&#39;}, bind={&#39;Major_Genre&#39;: alt.binding_select(options=genres), &#39;MPAA_Rating&#39;: alt.binding_radio(options=mpaa)} ) # scatter plot, modify opacity based on selection alt.Chart(df).mark_circle().add_selection( selection ).encode( x=&#39;Rotten_Tomatoes_Rating:Q&#39;, y=&#39;IMDB_Rating:Q&#39;, tooltip=&#39;Title:N&#39;, opacity=alt.condition(selection, alt.value(0.75), alt.value(0.05)) ) . Example 2: Tooltips . alt.Chart(df).mark_circle().add_selection( alt.selection_interval(bind=&#39;scales&#39;, encodings=[&#39;x&#39;]) ).encode( alt.X(&#39;Rotten_Tomatoes_Rating&#39;, type=&#39;quantitative&#39;), alt.Y(&#39;IMDB_Rating&#39;, type=&#39;quantitative&#39;, axis=alt.Axis(minExtent=30)), # y=alt.Y(&#39;IMDB_Rating:Q&#39;, ), # use min extent to stabilize axis title placement tooltip=[&#39;Title:N&#39;, &#39;Release_Date:N&#39;, &#39;IMDB_Rating:Q&#39;, &#39;Rotten_Tomatoes_Rating:Q&#39;] ).properties( width=500, height=400 ) . Example 3: More Tooltips . label = alt.selection_single( encodings=[&#39;x&#39;], # limit selection to x-axis value on=&#39;mouseover&#39;, # select on mouseover events nearest=True, # select data point nearest the cursor empty=&#39;none&#39; # empty selection includes no data points ) # define our base line chart of stock prices base = alt.Chart().mark_line().encode( alt.X(&#39;date:T&#39;), alt.Y(&#39;price:Q&#39;, scale=alt.Scale(type=&#39;log&#39;)), alt.Color(&#39;symbol:N&#39;) ) alt.layer( base, # base line chart # add a rule mark to serve as a guide line alt.Chart().mark_rule(color=&#39;#aaa&#39;).encode( x=&#39;date:T&#39; ).transform_filter(label), # add circle marks for selected time points, hide unselected points base.mark_circle().encode( opacity=alt.condition(label, alt.value(1), alt.value(0)) ).add_selection(label), # add white stroked text to provide a legible background for labels base.mark_text(align=&#39;left&#39;, dx=5, dy=-5, stroke=&#39;white&#39;, strokeWidth=2).encode( text=&#39;price:Q&#39; ).transform_filter(label), # add text labels for stock prices base.mark_text(align=&#39;left&#39;, dx=5, dy=-5).encode( text=&#39;price:Q&#39; ).transform_filter(label), data=stocks ).properties( width=500, height=400 ) . Data Tables . You can display tables per the usual way in your blog: . df[[&#39;Title&#39;, &#39;Worldwide_Gross&#39;, &#39;Production_Budget&#39;, &#39;Distributor&#39;, &#39;MPAA_Rating&#39;, &#39;IMDB_Rating&#39;, &#39;Rotten_Tomatoes_Rating&#39;]].head() . Title Worldwide_Gross Production_Budget Distributor MPAA_Rating IMDB_Rating Rotten_Tomatoes_Rating . 0 The Land Girls | 146083.0 | 8000000.0 | Gramercy | R | 6.1 | NaN | . 1 First Love, Last Rites | 10876.0 | 300000.0 | Strand | R | 6.9 | NaN | . 2 I Married a Strange Person | 203134.0 | 250000.0 | Lionsgate | None | 6.8 | NaN | . 3 Let&#39;s Talk About Sex | 373615.0 | 300000.0 | Fine Line | None | NaN | 13.0 | . 4 Slam | 1087521.0 | 1000000.0 | Trimark | R | 3.4 | 62.0 | . Images . Local Images . You can reference local images and they will be copied and rendered on your blog automatically. You can include these with the following markdown syntax: . ![](my_icons/fastai_logo.png) . . Remote Images . Remote images can be included with the following markdown syntax: . ![](https://image.flaticon.com/icons/svg/36/36686.svg) . . Animated Gifs . Animated Gifs work, too! . ![](https://upload.wikimedia.org/wikipedia/commons/7/71/ChessPawnSpecialMoves.gif) . . Captions . You can include captions with markdown images like this: . ![](https://www.fast.ai/images/fastai_paper/show_batch.png &quot;Credit: https://www.fast.ai/2020/02/13/fastai-A-Layered-API-for-Deep-Learning/&quot;) . . Other Elements . GitHub Flavored Emojis . Typing I give this post two :+1:! will render this: . I give this post two :+1:! . Tweetcards . Typing &gt; twitter: https://twitter.com/jakevdp/status/1204765621767901185?s=20 will render this: Altair 4.0 is released! https://t.co/PCyrIOTcvvTry it with: pip install -U altairThe full list of changes is at https://t.co/roXmzcsT58 ...read on for some highlights. pic.twitter.com/vWJ0ZveKbZ . &mdash; Jake VanderPlas (@jakevdp) December 11, 2019 . Youtube Videos . Typing &gt; youtube: https://youtu.be/XfoYk_Z5AkI will render this: . Boxes / Callouts . Typing &gt; Warning: There will be no second warning! will render this: . Warning: There will be no second warning! . Typing &gt; Important: Pay attention! It&#39;s important. will render this: . Important: Pay attention! It&#8217;s important. . Typing &gt; Tip: This is my tip. will render this: . Tip: This is my tip. . Typing &gt; Note: Take note of this. will render this: . Note: Take note of this. . Typing &gt; Note: A doc link to [an example website: fast.ai](https://www.fast.ai/) should also work fine. will render in the docs: . Note: A doc link to an example website: fast.ai should also work fine. . Footnotes . You can have footnotes in notebooks, however the syntax is different compared to markdown documents. This guide provides more detail about this syntax, which looks like this: . For example, here is a footnote {% fn 1 %}. And another {% fn 2 %} {{ &#39;This is the footnote.&#39; | fndetail: 1 }} {{ &#39;This is the other footnote. You can even have a [link](www.github.com)!&#39; | fndetail: 2 }} . For example, here is a footnote 1. . And another 2 . 1. This is the footnote.↩ . 2. This is the other footnote. You can even have a link!↩ .",
            "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/jupyter/2020/02/20/test.html",
            "relUrl": "/jupyter/2020/02/20/test.html",
            "date": " • Feb 20, 2020"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "This website is powered by fastpages 1. . a blogging platform that natively supports Jupyter notebooks in addition to other formats. &#8617; . |",
          "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://nachlord996.github.io/Machine-Learning-Portfolio/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}