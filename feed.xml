<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/feed.xml" rel="self" type="application/atom+xml" /><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/" rel="alternate" type="text/html" /><updated>2021-12-03T12:08:09-06:00</updated><id>https://nachlord996.github.io/Machine-Learning-Portfolio/feed.xml</id><title type="html">Ignacio Martínez</title><subtitle>En este portafolio están todos mis proyectos relacionados con Métodos de Aprendizaje Automático</subtitle><entry><title type="html">Un problema clásico de clasificación: UCI Iris mediante K-NN</title><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html" rel="alternate" type="text/html" title="Un problema clásico de clasificación: UCI Iris mediante K-NN" /><published>2021-12-01T00:00:00-06:00</published><updated>2021-12-01T00:00:00-06:00</updated><id>https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN%20Clasificaci%C3%B3n%20del%20Dataset%20Iris</id><author><name></name></author><category term="K Nearest Neighbours" /><category term="Rapidminer" /><category term="No Lineal" /><summary type="html">Dentro de las técnicas para clasificación en problemas no lineales, existe un grupo que utiliza la distancia entre predictores como elemento central. Esto parte de la idea de que los ejemplos que pertenecen a una misma clase, serán ciertamente más similares en cuanto a valores de los distintos predictores.</summary></entry><entry><title type="html">Validación de un modelo: Respuesta a una campaña de mail usando Naïve Bayes</title><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/na%C3%AFve%20bayes/validaci%C3%B3n%20del%20modelo/roc/lift%20charts/2021/11/28/Respuesta-a-una-campa%C3%B1a-de-mail-usando-Naive-Bayes.html" rel="alternate" type="text/html" title="Validación de un modelo: Respuesta a una campaña de mail usando Naïve Bayes" /><published>2021-11-28T00:00:00-06:00</published><updated>2021-11-28T00:00:00-06:00</updated><id>https://nachlord996.github.io/Machine-Learning-Portfolio/na%C3%AFve%20bayes/validaci%C3%B3n%20del%20modelo/roc/lift%20charts/2021/11/28/Respuesta%20a%20una%20campa%C3%B1a%20de%20mail%20usando-Naive-Bayes</id><author><name></name></author><category term="Naïve Bayes" /><category term="Validación del modelo" /><category term="ROC" /><category term="Lift Charts" /><summary type="html">La calidad de un modelo de Machine Learning no se evalúa exclusivamente con los resultados que este genera durante su entrenamiento y validación. La aplicabilidad de cualquier modelo debe considerar múltiples métricas que demuestren su efectividad en la realidad.</summary></entry><entry><title type="html">Revisión de técnincas de aprendizaje no supervisado: K-means</title><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/clustering/k-means/rapidminer/2021/11/28/Revision-de-t%C3%A9cnicas-de-aprendizaje-no-supervisado-k-means.html" rel="alternate" type="text/html" title="Revisión de técnincas de aprendizaje no supervisado: K-means" /><published>2021-11-28T00:00:00-06:00</published><updated>2021-11-28T00:00:00-06:00</updated><id>https://nachlord996.github.io/Machine-Learning-Portfolio/clustering/k-means/rapidminer/2021/11/28/Revision-de-t%C3%A9cnicas-de-aprendizaje-no-supervisado-k-means</id><author><name></name></author><category term="Clustering" /><category term="K-means" /><category term="Rapidminer" /><summary type="html">Los métodos de aprendizaje automático se pueden dividir en dos grandes enfoques, los supervisados y los no supervisados. El primero se basa en el uso de Datasets etiquetados. Esta información es utilizado en el entrenamiento de un modelo para que este aprenda las relaciones que existen entre los datos de entrada y una variable objetivo. Por esto mismo, este enfoque se centra en generar la capacidad de predicción a partir de ejemplos nuevos, con una precisión aceptable.</summary></entry><entry><title type="html">Caso de Estudio: Detección de enfermedad cardíaca</title><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/caso%20de%20estudio/%C3%A1rbol%20de%20decisi%C3%B3n/random%20forest/rapidminer/preparaci%C3%B3n%20de%20los%20datos/entrenamiento/2021/11/25/Caso-de-Estudio-Predicci%C3%B3n-de-enfermedad-del-coraz%C3%B3n.html" rel="alternate" type="text/html" title="Caso de Estudio: Detección de enfermedad cardíaca" /><published>2021-11-25T00:00:00-06:00</published><updated>2021-11-25T00:00:00-06:00</updated><id>https://nachlord996.github.io/Machine-Learning-Portfolio/caso%20de%20estudio/%C3%A1rbol%20de%20decisi%C3%B3n/random%20forest/rapidminer/preparaci%C3%B3n%20de%20los%20datos/entrenamiento/2021/11/25/Caso%20de%20Estudio%20-%20Predicci%C3%B3n%20de%20enfermedad%20del%20coraz%C3%B3n</id><author><name></name></author><category term="Caso de estudio" /><category term="Árbol de decisión" /><category term="Random Forest" /><category term="Rapidminer" /><category term="Preparación de los datos" /><category term="Entrenamiento" /><summary type="html">Contexto del problema</summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="https://nachlord996.github.io/Machine-Learning-Portfolio/images/Caso-de-estudio-logo.jpg" /><media:content medium="image" url="https://nachlord996.github.io/Machine-Learning-Portfolio/images/Caso-de-estudio-logo.jpg" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">Estudio Del Efecto De La Estandarización Y Normalización</title><link href="https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/24/Estudio-del-efecto-de-la-estandarizaci%C3%B3n-y-normalizaci%C3%B3n.html" rel="alternate" type="text/html" title="Estudio Del Efecto De La Estandarización Y Normalización" /><published>2021-11-24T00:00:00-06:00</published><updated>2021-11-24T00:00:00-06:00</updated><id>https://nachlord996.github.io/Machine-Learning-Portfolio/2021/11/24/Estudio-del-efecto-de-la-estandarizaci%C3%B3n-y-normalizaci%C3%B3n</id><author><name></name></author><summary type="html">Efecto de la estandarización y normalización</summary></entry></feed>