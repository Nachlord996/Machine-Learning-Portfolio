<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1">
  <meta name="twitter:card" content="summary_large_image" /><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>Un problema clásico de clasificación: UCI Iris mediante K-NN | Ignacio Martínez</title>
<meta name="generator" content="Jekyll v4.1.1" />
<meta property="og:title" content="Un problema clásico de clasificación: UCI Iris mediante K-NN" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Se analiza el Dataset Iris de UCI para aplicar K Nearest Neighbours." />
<meta property="og:description" content="Se analiza el Dataset Iris de UCI para aplicar K Nearest Neighbours." />
<link rel="canonical" href="https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html" />
<meta property="og:url" content="https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html" />
<meta property="og:site_name" content="Ignacio Martínez" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2021-12-01T00:00:00-06:00" />
<script type="application/ld+json">
{"url":"https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html","@type":"BlogPosting","headline":"Un problema clásico de clasificación: UCI Iris mediante K-NN","dateModified":"2021-12-01T00:00:00-06:00","datePublished":"2021-12-01T00:00:00-06:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://nachlord996.github.io/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html"},"description":"Se analiza el Dataset Iris de UCI para aplicar K Nearest Neighbours.","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->
<link rel="stylesheet" href="/Machine-Learning-Portfolio/assets/css/style.css"><link type="application/atom+xml" rel="alternate" href="https://nachlord996.github.io/Machine-Learning-Portfolio/feed.xml" title="Ignacio Martínez" /><link rel="shortcut icon" type="image/x-icon" href="/Machine-Learning-Portfolio/images/favicon.ico"><link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/Primer/15.2.0/primer.css" integrity="sha512-xTz2ys4coGAOz8vuV1NcQBkgVmKhsSEtjbqyMJbBHRplFuvKIUo6xhLHpAyPt9mfR6twHJgn9OgVLuqOvjeBhg==" crossorigin="anonymous" />
<link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.14.0/css/all.min.css" integrity="sha512-1PKOgIY59xJ8Co8+NE6FZ+LOAZKjy+KY8iq0G4B3CyeY6wYHN3yt9PW0XpSriVlkMXe40PTKnXrLnZ9+fkDaog==" crossorigin="anonymous" />

<script>
function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title") && (el.className != "emoji")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
}
window.onload = wrap_img;
</script>

<script>
    document.addEventListener("DOMContentLoaded", function(){
    // add link icon to anchor tags
    var elem = document.querySelectorAll(".anchor-link")
    elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
    });
</script>
</head>
<body><header class="site-header">

  <div class="wrapper"><a class="site-title" rel="author" href="/Machine-Learning-Portfolio/">Ignacio Martínez</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/Machine-Learning-Portfolio/about/">Sobre mi</a><a class="page-link" href="/Machine-Learning-Portfolio/search/">Search</a><a class="page-link" href="/Machine-Learning-Portfolio/categories/">Tags</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">Un problema clásico de clasificación: UCI Iris mediante K-NN</h1><p class="page-description">Se analiza el Dataset Iris de UCI para aplicar K Nearest Neighbours.</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2021-12-01T00:00:00-06:00" itemprop="datePublished">
        Dec 1, 2021
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      2 min read
    
</span></p>

    
      <p class="category-tags"><i class="fas fa-tags category-tags-icon"></i></i> 
      
        <a class="category-tags-link" href="/Machine-Learning-Portfolio/categories/#K Nearest Neighbours">K Nearest Neighbours</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Machine-Learning-Portfolio/categories/#Rapidminer">Rapidminer</a>
        &nbsp;
      
        <a class="category-tags-link" href="/Machine-Learning-Portfolio/categories/#No Lineal">No Lineal</a>
        
      
      </p>
    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h2"><a href="#contexto">Contexto</a></li>
<li class="toc-entry toc-h2"><a href="#datos">Datos</a></li>
<li class="toc-entry toc-h2"><a href="#modelo">Modelo</a></li>
<li class="toc-entry toc-h2"><a href="#evaluación">Evaluación</a></li>
</ul><p>Dentro de las técnicas para clasificación en problemas no lineales, existe un grupo que utiliza la distancia entre predictores como elemento central. Esto parte de la idea de que los ejemplos que pertenecen a una misma clase, serán ciertamente más similares en cuanto a valores de los distintos predictores.</p>

<p><em>K-nearest Neighbours</em> o simplemente <strong>K-NN</strong>, es un algoritmo para problemas de clasificación que se basa en almacenar la información del dataset y evaluar nuevos ejemplos a partir de un cálculo simple de distancia. La clase predicha de un elemento estará dada por los K elementos (previamente clasificados) más cercanos.</p>

<h2 id="contexto">
<a class="anchor" href="#contexto" aria-hidden="true"><span class="octicon octicon-link"></span></a>Contexto</h2>

<p>Para este ejercicio se utilizará como base el Dataset Iris de UCI, el mismo es de acceso totalmente público y gratuito. En Rapidminer generaré un flujo que entrene un modelo a partir de los datos de Iris, en este caso bajo la proporción <em>70/30</em>, para luego testearlo, revisar los resultados y las distintas opciones de configuración que el modelo ofrece.</p>

<h2 id="datos">
<a class="anchor" href="#datos" aria-hidden="true"><span class="octicon octicon-link"></span></a>Datos</h2>

<p>El Dataset Iris es bastante reducido, cuenta solamente con 150 ejemplos. Además de la variable objetivo, existen 4 predictores distintos relacionados con medidas de las flores observadas en la realidad.</p>

<p>El dataset está completamente etiquetado y ningún predictor tiene valores faltantes. La siguiente tabla resume las variables disponibles en el Dataset:</p>

<table>
  <thead>
    <tr>
      <th>Variable</th>
      <th>Tipo de dato</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Largo Sépalo</td>
      <td>Numérico</td>
    </tr>
    <tr>
      <td>Ancho del Sépalo</td>
      <td>Numérico</td>
    </tr>
    <tr>
      <td>Largo del Pétalo</td>
      <td>Numérico</td>
    </tr>
    <tr>
      <td>Ancho del Pétalo</td>
      <td>Numérico</td>
    </tr>
  </tbody>
</table>

<p>La variables objetivo es del tipo Polinomial y tiene <strong>3 valores</strong> posibles: Iris Setosa, Iris Versi-color e Iris Virginica.</p>

<p>Examinando los gráficos de tipo plot entre los predictores, resulta interesante la agrupación generada en el espacio de las clases para las variables <strong>“Largo Pétalo”</strong> y <strong>“Ancho Pétalo”</strong>. Además, estos dos predictores son los que tienen mayor correlación con la variable objetivo.</p>

<p><img src="/Machine-Learning-Portfolio/images/KNN3.png" alt="" title="Plot de Largo Pétalo y Ancho Pétalo"></p>

<h2 id="modelo">
<a class="anchor" href="#modelo" aria-hidden="true"><span class="octicon octicon-link"></span></a>Modelo</h2>

<p>En Rapidminer, se importa el Dataset de Iris. En primer lugar, es necesario eliminar los predictores que no vamos a utilizar para el ejercicio. Luego, se realiza la separación de los datos mediante muestreo aleatorio en 70% para Entrenamiento y 30% para Test, esto se puede realizar mediante el operador <em>“Split Data”</em>.</p>

<p>Agregamos el operador de K-NN con la configuración que viene por defecto, seguido de un <em>“Apply Model”</em> para predecir los valores de la clase objetivo para el 30% reservado para Test.</p>

<p>El flujo debería verse así:</p>

<p><img src="/Machine-Learning-Portfolio/images/KNN1.png" alt="" title="Flujo de Rapidminer para apicar K-NN al Dataset Iris"></p>

<h2 id="evaluación">
<a class="anchor" href="#evaluaci%C3%B3n" aria-hidden="true"><span class="octicon octicon-link"></span></a>Evaluación</h2>

<p>Al ejecutar el modelo, vemos que los resultados obtenidos son muy positivos. Esto quiere decir que nuestro modelo aprovechó bien la correlación entre predictores y la separación en el hyperespacio de las clases objetivo.</p>

<p>Aquí la matriz de confusión para esta ejecución inicial:
<img src="/Machine-Learning-Portfolio/images/KNN2.png" alt="" title="Matriz de confusión"></p>

<p>Vale destacar que el operador de K-NN ofrece distintos métodos para el cálculo de la distincia, los cuales podrían ser interesantes para otras situaciones donde la separación no sea tan clara o el resultado obtenido no sea tan bueno.</p>

<ul>
  <li>Distancia de Chebychev</li>
  <li>Distancia Euclideana</li>
  <li>Similitud Coseno</li>
  <li>Distancia de Manhattan</li>
</ul>

<p>También, Rapidminer ofrece la posibilidad de ponderar el voto en la selección de la clase objetivo. Esto se puede establecer mediante un <em>switch</em> el cual determina si la distancia importa en la decisión. Es decir, aquellos vecinos cercanos tendrán una mayor incidencia en la clase escogida.</p>

  </div><a class="u-url" href="/Machine-Learning-Portfolio/k%20nearest%20neighbours/rapidminer/no%20lineal/2021/12/01/KNN-Clasificaci%C3%B3n-del-Dataset-Iris.html" hidden></a>
</article>

      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/Machine-Learning-Portfolio/"></data>

  <div class="wrapper">

    <div class="footer-col-wrapper">
      <div class="footer-col">
        <p class="feed-subscribe">
          <a href="/Machine-Learning-Portfolio/feed.xml">
            <svg class="svg-icon orange">
              <use xlink:href="/Machine-Learning-Portfolio/assets/minima-social-icons.svg#rss"></use>
            </svg><span>Subscribe</span>
          </a>
        </p>
      </div>
      <div class="footer-col">
        <p>En este portafolio están todos mis proyectos relacionados con Métodos de Aprendizaje Automático</p>
      </div>
    </div>

    <div class="social-links"><ul class="social-media-list"><li><a rel="me" href="https://github.com/Nachlord996" title="Nachlord996"><svg class="svg-icon grey"><use xlink:href="/Machine-Learning-Portfolio/assets/minima-social-icons.svg#github"></use></svg></a></li></ul>
</div>

  </div>

</footer>
</body>

</html>
